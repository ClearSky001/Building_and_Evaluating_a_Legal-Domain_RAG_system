# -*- coding: utf-8 -*-
import os
import sys
import json
import time
import random
import argparse
import csv
from dataclasses import dataclass, asdict, field
from datetime import datetime
from typing import List, Dict, Any, Optional

import numpy as np
from dotenv import load_dotenv

# LangChain
from langchain_openai import ChatOpenAI
from langchain_core.documents import Document
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.vectorstores import VectorStore
from langchain_core.embeddings import Embeddings

# SentenceTransformer
from sentence_transformers import SentenceTransformer

# Additional imports for retriever
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# -----------------------------
# 0) Experiment Config & Utils
# -----------------------------

@dataclass
class ExperimentConfig:
    # data/index
    embeddings_file: str = "output_chunks_with_embeddings.json"
    index_version: str = "v2025-08-16"
    retriever_id: str = "naive_cosine_e5"   # "naive_cosine_e5", "bm25", "tfidf", "hybrid_rrf"
    distance_metric: str = "cosine"
    embedding_model: str = "intfloat/multilingual-e5-large-instruct"
    
    # BM25 parameters
    bm25_k1: float = 1.5
    bm25_b: float = 0.75
    
    # Hybrid retriever weights
    hybrid_weights: List[float] = field(default_factory=lambda: [0.5, 0.5])  # Equal weights for dense/sparse

    # k-values
    k_ctx: int = 5         # generationì— ë“¤ì–´ê°ˆ ì»¨í…ìŠ¤íŠ¸ ìˆ˜
    k_in: int = 50         # ë¦¬ë­ì»¤ìš© í›„ë³´êµ° ë¤í”„ ìˆ˜
    k_dbg: int = 10        # ë””ë²„ê¹…/í”„ë¦°íŠ¸ìš© ì¡°íšŒ ìˆ˜

    # LLM
    llm_model: str = "gpt-4o-mini"
    temperature: float = 0.0

    # seeds
    seed: int = 42

    # logging
    out_dir: str = "exp_outputs"
    exp_name: str = "retriever_baseline"

    # langsmith (optional)
    tracing_v2: str = "true"
    langsmith_endpoint: str = ""
    langsmith_api_key: str = ""


def set_seed(seed: int):
    random.seed(seed)
    np.random.seed(seed)
    try:
        import torch
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)
        # torch.backends.cudnn.deterministic = True  # (ì˜µì…˜) ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥
        # torch.backends.cudnn.benchmark = False     # (ì˜µì…˜)
    except Exception:
        pass


def now_kst_iso() -> str:
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def ensure_dir(path: str):
    os.makedirs(path, exist_ok=True)


def save_json(obj: Any, path: str):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)


# -----------------------------
# 1) Embeddings Wrapper
# -----------------------------

class SentenceTransformerEmbeddings(Embeddings):
    """SentenceTransformerë¥¼ LangChain Embeddings ì¸í„°í˜ì´ìŠ¤ë¡œ ë˜í•‘"""

    def __init__(self, model_name: str = "intfloat/multilingual-e5-large-instruct", seed: int = 42):
        # deterministicì„ ìµœëŒ€í•œ ìœ ì§€í•˜ë ¤ê³  seedë¥¼ ì•ì„œ ì„¤ì •
        # SentenceTransformer ìì²´ëŠ” ì¶”ë¡  ì‹œ ë¹„ê²°ì •ì„±ì´ ê±°ì˜ ì—†ì§€ë§Œ, ì•ˆì „í•˜ê²Œ ì‹œë“œ ê³ ì •
        self.model_name = model_name
        self.model = SentenceTransformer(model_name)

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        embeddings = self.model.encode(texts, normalize_embeddings=False, convert_to_numpy=True).tolist()
        return embeddings

    def embed_query(self, text: str) -> List[float]:
        # E5 ëª¨ë¸ì€ ì¿¼ë¦¬ì— "query: " ì ‘ë‘ì‚¬ ê¶Œì¥
        query_text = f"query: {text}"
        embedding = self.model.encode([query_text], normalize_embeddings=False, convert_to_numpy=True)[0].tolist()
        return embedding


# -----------------------------
# 2) Naive VectorStore (cosine)
# -----------------------------

class NaiveVectorStore(VectorStore):
    """Naive VectorStore - LangChain í˜¸í™˜ ë²„ì „ (cosine ìœ ì‚¬ë„)"""

    def __init__(self, documents: List[Document], embeddings: List[List[float]], embedding_function: Embeddings):
        self.documents = documents
        self.embedding_function = embedding_function
        mat = np.array(embeddings, dtype=np.float32)

        # 0 division ë°©ì§€
        norms = np.linalg.norm(mat, axis=1, keepdims=True)
        norms[norms == 0] = 1e-12
        self._embeddings_matrix = mat / norms

    def add_texts(self, texts: List[str], metadatas: Optional[List[dict]] = None, **kwargs) -> List[str]:
        raise NotImplementedError("add_textsëŠ” í˜„ì¬ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    def similarity_search_by_vector(self, embedding: List[float], k: int = 4, **kwargs) -> List[Document]:
        query_vector = np.array(embedding, dtype=np.float32)
        qnorm = np.linalg.norm(query_vector)
        if qnorm == 0:
            qnorm = 1e-12
        query_norm = query_vector / qnorm

        sims = np.dot(self._embeddings_matrix, query_norm)
        # ìƒìœ„ kê°œ
        top_k_idx = sims.argsort()[::-1][:k]
        return [self.documents[i] for i in top_k_idx]

    def similarity_search(self, query: str, k: int = 4, **kwargs) -> List[Document]:
        qemb = self.embedding_function.embed_query(query)
        return self.similarity_search_by_vector(qemb, k, **kwargs)

    def similarity_search_with_score(self, query: str, k: int = 4, **kwargs) -> List[tuple]:
        qemb = self.embedding_function.embed_query(query)
        query_vector = np.array(qemb, dtype=np.float32)
        qnorm = np.linalg.norm(query_vector)
        if qnorm == 0:
            qnorm = 1e-12
        query_norm = query_vector / qnorm

        sims = np.dot(self._embeddings_matrix, query_norm)
        top_k_idx = sims.argsort()[::-1][:k]

        results = []
        for idx in top_k_idx:
            results.append((self.documents[idx], float(sims[idx])))
        return results

    @classmethod
    def from_texts(cls, texts: List[str], embedding: Embeddings, metadatas: Optional[List[dict]] = None, **kwargs):
        raise NotImplementedError("from_textsëŠ” í˜„ì¬ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


# -----------------------------
# 2.5) TF-IDF VectorStore
# -----------------------------

class TFIDFVectorStore(VectorStore):
    """TF-IDF ê¸°ë°˜ VectorStore"""
    
    def __init__(self, documents: List[Document], embedding_function: Embeddings = None):
        self.documents = documents
        self.embedding_function = embedding_function  # TF-IDFëŠ” ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„±ì„ ìœ„í•´
        
        # TF-IDF ë²¡í„°í™”
        texts = [doc.page_content for doc in documents]
        self.vectorizer = TfidfVectorizer(
            ngram_range=(1, 2),  # unigram + bigram
            max_features=10000,
            min_df=2,
            max_df=0.95
        )
        self.tfidf_matrix = self.vectorizer.fit_transform(texts)
    
    def add_texts(self, texts: List[str], metadatas: Optional[List[dict]] = None, **kwargs) -> List[str]:
        raise NotImplementedError("add_textsëŠ” í˜„ì¬ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def similarity_search_by_vector(self, embedding: List[float], k: int = 4, **kwargs) -> List[Document]:
        raise NotImplementedError("TF-IDFëŠ” ë²¡í„° ê²€ìƒ‰ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    def similarity_search(self, query: str, k: int = 4, **kwargs) -> List[Document]:
        query_vec = self.vectorizer.transform([query])
        similarities = cosine_similarity(query_vec, self.tfidf_matrix).flatten()
        top_k_idx = similarities.argsort()[::-1][:k]
        return [self.documents[i] for i in top_k_idx]
    
    def similarity_search_with_score(self, query: str, k: int = 4, **kwargs) -> List[tuple]:
        query_vec = self.vectorizer.transform([query])
        similarities = cosine_similarity(query_vec, self.tfidf_matrix).flatten()
        top_k_idx = similarities.argsort()[::-1][:k]
        
        results = []
        for idx in top_k_idx:
            results.append((self.documents[idx], float(similarities[idx])))
        return results
    
    @classmethod
    def from_texts(cls, texts: List[str], embedding: Embeddings, metadatas: Optional[List[dict]] = None, **kwargs):
        raise NotImplementedError("from_textsëŠ” í˜„ì¬ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


# -----------------------------
# 3) RAG System
# -----------------------------

class LegalRAGSystem:
    """ë²•ë¥  ë¬¸ì„œ RAG ì‹œìŠ¤í…œ"""

    def __init__(self, cfg: ExperimentConfig):
        self.cfg = cfg
        self.documents: List[Document] = []
        self.vectorstore: Optional[NaiveVectorStore] = None
        self.retriever = None
        self.rag_chain = None
        self.llm = None
        self.embedding_model: Optional[SentenceTransformerEmbeddings] = None

        # í™˜ê²½
        self._setup_environment()
        # seed
        set_seed(self.cfg.seed)
        # ì´ˆê¸°í™”
        self._initialize_system()

    # --- env & IO ---

    def _setup_environment(self):
        load_dotenv()
        os.environ["LANGCHAIN_TRACING_V2"] = self.cfg.tracing_v2
        if self.cfg.langsmith_endpoint:
            os.environ["LANGCHAIN_ENDPOINT"] = self.cfg.langsmith_endpoint
        if self.cfg.langsmith_api_key:
            os.environ["LANGCHAIN_API_KEY"] = self.cfg.langsmith_api_key

        ensure_dir(self.cfg.out_dir)
        # ì‹¤í—˜ ë©”íƒ€ ì €ì¥ - íƒ€ì„ìŠ¤íƒ¬í”„ì™€ retriever_id í¬í•¨
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        meta_filename = f"{self.cfg.exp_name}_{self.cfg.retriever_id}_{timestamp}_config.json"
        meta_path = os.path.join(self.cfg.out_dir, meta_filename)
        save_json(asdict(self.cfg), meta_path)
        print(f"âœ… í™˜ê²½/ì„¤ì • ì¤€ë¹„ ì™„ë£Œ, config ì €ì¥: {meta_path}")

    def _load_embeddings_data(self) -> tuple:
        print(f"ğŸ“‚ ì„ë² ë”© ë°ì´í„° ë¡œë“œ: {self.cfg.embeddings_file}")
        with open(self.cfg.embeddings_file, "r", encoding="utf-8") as f:
            chunk_data = json.load(f)

        documents, embeddings_array = [], []
        for item in chunk_data:
            doc = Document(
                page_content=item["text"],
                metadata={
                    "filename": item["filename"],
                    "chunk_index": item["chunk_index"],
                    "source": f"{item['filename']}_chunk_{item['chunk_index']}"
                }
            )
            documents.append(doc)
            embeddings_array.append(item["embedding"])

        print(f"âœ… ë¬¸ì„œ ì²­í¬: {len(documents)}ê°œ")
        if documents:
            print(f"ğŸ“„ ì²« ì²­í¬: {documents[0].page_content[:100]}...")
        return documents, embeddings_array

    def _create_vectorstore(self, documents: List[Document], embeddings_array: List[List[float]]):
        print(f"ğŸ”§ VectorStore ìƒì„± (type: {self.cfg.retriever_id})...")
        self.embedding_model = SentenceTransformerEmbeddings(model_name=self.cfg.embedding_model, seed=self.cfg.seed)
        
        if self.cfg.retriever_id in ["naive_cosine_e5", "hybrid_rrf"]:
            vs = NaiveVectorStore(documents=documents, embeddings=embeddings_array, embedding_function=self.embedding_model)
        elif self.cfg.retriever_id == "tfidf":
            vs = TFIDFVectorStore(documents=documents, embedding_function=self.embedding_model)
        else:
            # BM25ëŠ” vectorstoreê°€ ì•„ë‹ˆë¯€ë¡œ None ë°˜í™˜
            vs = None
            
        if vs:
            print(f"âœ… VectorStore ì¤€ë¹„(ë¬¸ì„œ ìˆ˜: {len(documents)})")
        return vs

    # --- RAG ---
    
    def _setup_retriever(self):
        """retriever_idì— ë”°ë¼ ì ì ˆí•œ ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì •"""
        print(f"ğŸ”§ Retriever ì„¤ì • ì¤‘... (type: {self.cfg.retriever_id})")
        
        if self.cfg.retriever_id == "naive_cosine_e5":
            self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": self.cfg.k_ctx})
            
        elif self.cfg.retriever_id == "bm25":
            # BM25 Retriever
            texts = [doc.page_content for doc in self.documents]
            self.retriever = BM25Retriever.from_texts(
                texts=texts,
                metadatas=[doc.metadata for doc in self.documents],
                k=self.cfg.k_ctx,
                bm25_params={"k1": self.cfg.bm25_k1, "b": self.cfg.bm25_b}
            )
            
        elif self.cfg.retriever_id == "tfidf":
            self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": self.cfg.k_ctx})
            
        elif self.cfg.retriever_id == "hybrid_rrf":
            # Hybrid retriever using Reciprocal Rank Fusion
            # Dense retriever (embedding-based)
            dense_retriever = self.vectorstore.as_retriever(search_kwargs={"k": self.cfg.k_ctx * 2})
            
            # Sparse retriever (BM25)
            texts = [doc.page_content for doc in self.documents]
            sparse_retriever = BM25Retriever.from_texts(
                texts=texts,
                metadatas=[doc.metadata for doc in self.documents],
                k=self.cfg.k_ctx * 2,
                bm25_params={"k1": self.cfg.bm25_k1, "b": self.cfg.bm25_b}
            )
            
            # Ensemble with RRF
            weights = self.cfg.hybrid_weights or [0.5, 0.5]
            self.retriever = EnsembleRetriever(
                retrievers=[dense_retriever, sparse_retriever],
                weights=weights,
                search_kwargs={"k": self.cfg.k_ctx}
            )
        else:
            raise ValueError(f"Unknown retriever_id: {self.cfg.retriever_id}")
            
        print(f"âœ… Retriever ì¤€ë¹„ ì™„ë£Œ: {self.cfg.retriever_id}")

    def _setup_rag_components(self):
        print("âš™ï¸ RAG ì»´í¬ë„ŒíŠ¸ êµ¬ì„±...")
        # RetrieverëŠ” ì´ë¯¸ _setup_retriever()ì—ì„œ ì„¤ì •ë¨

        legal_prompt = PromptTemplate.from_template(
            """ë‹¹ì‹ ì€ ë¶€ë™ì‚°ì„¸ë²• ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë²•ë¥  ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ğŸ“‹ **ì°¸ê³  ë¬¸ì„œ:**
{context}

ğŸ“ **ë‹µë³€ ì§€ì¹¨:**
1. ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì— ê·¼ê±°í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
2. ê´€ë ¨ ë²•ë ¹ ì¡°ë¬¸ì´ë‚˜ ì¡°í•­ì„ ëª…ì‹œí•´ì£¼ì„¸ìš”
3. ë²•ë¥ ì  ê·¼ê±°ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”
4. ë¬¸ì„œì—ì„œ ëª…í™•í•œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´ "ì œê³µëœ ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë§í•˜ì„¸ìš”
5. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”

â“ **ì§ˆë¬¸:** {question}

ğŸ’¡ **ë‹µë³€:**"""
        )

        self.llm = ChatOpenAI(
            model=self.cfg.llm_model,
            temperature=self.cfg.temperature,
            openai_api_key=os.getenv("OPENAI_API_KEY"),
        )

        def format_docs(docs):
            formatted = []
            for i, doc in enumerate(docs, 1):
                src = doc.metadata.get("source", "unknown")
                content = doc.page_content.strip()
                formatted.append(f"ğŸ“„ **ë¬¸ì„œ {i}** ({src})\n{content}")
            return "\n\n" + "\n\n".join(formatted) + "\n\n"

        self.rag_chain = (
            {
                "context": self.retriever | format_docs,
                "question": RunnablePassthrough(),
            }
            | legal_prompt
            | self.llm
            | StrOutputParser()
        )
        print("âœ… RAG ì²´ì¸ êµ¬ì„± ì™„ë£Œ")

    def _initialize_system(self):
        print("ğŸš€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘")
        try:
            self.documents, emb = self._load_embeddings_data()
            self.vectorstore = self._create_vectorstore(self.documents, emb)
            self._setup_retriever()
            self._setup_rag_components()
            print("ğŸ‰ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            raise

    # -----------------------------
    # 4) Utilities (dump/report)
    # -----------------------------

    def dump_candidates(self, query: str, k_in: Optional[int] = None, filename: Optional[str] = None):
        """ë¦¬ë­ì»¤ íŒ€ ê³µì •ë¹„êµìš© í›„ë³´êµ° ë¤í”„(JSONL)"""
        k = k_in if k_in is not None else self.cfg.k_in
        out_name = filename or f"cands_{self.cfg.retriever_id}_{self.cfg.index_version}.jsonl"
        path = os.path.join(self.cfg.out_dir, out_name)

        t0 = time.time()
        
        # retriever_idì— ë”°ë¼ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í›„ë³´êµ° ìƒì„±
        if self.cfg.retriever_id == "bm25":
            # BM25ëŠ” scoreë¥¼ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ìˆœìœ„ë¥¼ scoreë¡œ ì‚¬ìš©
            docs = self.retriever.get_relevant_documents(query)[:k]
            results = [(doc, 1.0 / (i + 1)) for i, doc in enumerate(docs)]
        elif self.cfg.retriever_id == "hybrid_rrf":
            # Hybridë„ ë§ˆì°¬ê°€ì§€ë¡œ ìˆœìœ„ ê¸°ë°˜ ìŠ¤ì½”ì–´
            docs = self.retriever.get_relevant_documents(query)[:k]
            results = [(doc, 1.0 / (i + 1)) for i, doc in enumerate(docs)]
        else:
            # vectorstore ê¸°ë°˜ ë¦¬íŠ¸ë¦¬ë²„ë“¤
            results = self.vectorstore.similarity_search_with_score(query, k=k)
            
        dt = time.time() - t0

        with open(path, "w", encoding="utf-8") as f:
            for rank, (doc, score) in enumerate(results, start=1):
                rec = {
                    "timestamp": now_kst_iso(),
                    "query": query,
                    "rank": rank,
                    "score": score,
                    "text": doc.page_content,
                    "source": doc.metadata.get("source"),
                    "retriever_id": self.cfg.retriever_id,
                    "index_version": self.cfg.index_version,
                    "distance_metric": self.cfg.distance_metric,
                    "embedding_model": self.cfg.embedding_model,
                    "k_in": k,
                    "seed": self.cfg.seed,
                }
                f.write(json.dumps(rec, ensure_ascii=False) + "\n")

        print(f"ğŸ—‚ï¸ í›„ë³´êµ° {k}ê°œ ì €ì¥: {path} (latency: {dt:.3f}s)")
        return path, dt, results[0][1] if results else None

    def write_report_row(self, csv_name: str, row: Dict[str, Any]):
        path = os.path.join(self.cfg.out_dir, csv_name)
        new_file = not os.path.exists(path)
        with open(path, "a", newline="", encoding="utf-8") as f:
            w = csv.DictWriter(f, fieldnames=list(row.keys()))
            if new_file:
                w.writeheader()
            w.writerow(row)
        return path

    # -----------------------------
    # 5) Interactive & Tests
    # -----------------------------

    def test_similarity_search(self, query: str = "ì¢…í•©ë¶€ë™ì‚°ì„¸ì˜ ëª©ì ", k: Optional[int] = None):
        k = k or self.cfg.k_dbg
        print(f"\nğŸ” ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ | k={k} | query='{query}' | retriever={self.cfg.retriever_id}")
        
        if self.cfg.retriever_id == "bm25" or self.cfg.retriever_id == "hybrid_rrf":
            docs = self.retriever.get_relevant_documents(query)[:k]
        else:
            if self.vectorstore is None:
                print("âŒ VectorStore ë¯¸ì´ˆê¸°í™”")
                return []
            docs = self.vectorstore.similarity_search(query, k=k)
            
        for i, d in enumerate(docs, 1):
            print(f"[{i}] {d.metadata.get('source')} :: {d.page_content[:150]}...")
        return docs

    def test_similarity_search_with_score(self, query: str = "ì¢…í•©ë¶€ë™ì‚°ì„¸ì˜ ëª©ì ", k: Optional[int] = None):
        k = k or self.cfg.k_dbg
        print(f"\nğŸ” ì ìˆ˜ í¬í•¨ ìœ ì‚¬ë„ ê²€ìƒ‰ | k={k} | query='{query}' | retriever={self.cfg.retriever_id}")
        
        if self.cfg.retriever_id == "bm25" or self.cfg.retriever_id == "hybrid_rrf":
            docs = self.retriever.get_relevant_documents(query)[:k]
            results = [(doc, 1.0 / (i + 1)) for i, doc in enumerate(docs)]
        else:
            if self.vectorstore is None:
                print("âŒ VectorStore ë¯¸ì´ˆê¸°í™”")
                return []
            results = self.vectorstore.similarity_search_with_score(query, k=k)
            
        for i, (d, s) in enumerate(results, 1):
            print(f"[{i}] score={s:.4f} | {d.metadata.get('source')} :: {d.page_content[:150]}...")
        return results

    def ask_question(self, question: str, show_sources: bool = True) -> str:
        print(f"\nğŸ¤– ì§ˆë¬¸: {question}")
        try:
            if show_sources:
                docs = self.retriever.invoke(question)
                print("ğŸ“š ì°¸ê³  ë¬¸ì„œ:")
                for i, d in enumerate(docs, 1):
                    print(f"  {i}. {d.metadata.get('source')}")
            resp = self.rag_chain.invoke(question)
            print("\nğŸ’¡ ë‹µë³€:\n" + resp)
            return resp
        except Exception as e:
            msg = f"âŒ ë‹µë³€ ì˜¤ë¥˜: {e}"
            print(msg)
            return msg

    def run_test_questions(self):
        tests = [
            "ì¢…í•©ë¶€ë™ì‚°ì„¸ë²•ì˜ ëª©ì ì„ ë²•ë ¹ ì¡°ë¬¸ì„ ê·¼ê±°ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.",
            "ì¢…í•©ë¶€ë™ì‚°ì„¸ ë‚©ì„¸ì˜ë¬´ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?",
            "ì¢…í•©ë¶€ë™ì‚°ì„¸ ê³¼ì„¸ëŒ€ìƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
        ]
        print("\n" + "="*60)
        print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì‹¤í–‰")
        print("="*60)
        for i, q in enumerate(tests, 1):
            print("\n" + "="*60)
            print(f"í…ŒìŠ¤íŠ¸ {i}: {q}")
            print("="*60)
            self.ask_question(q)

# -----------------------------
# 6) CLI / Main
# -----------------------------

def build_config_from_args() -> ExperimentConfig:
    p = argparse.ArgumentParser()
    p.add_argument("--embeddings_file", type=str, default="output_chunks_with_embeddings.json")
    p.add_argument("--index_version", type=str, default="v2025-08-16")
    p.add_argument("--retriever_id", type=str, default="naive_cosine_e5")
    p.add_argument("--embedding_model", type=str, default="intfloat/multilingual-e5-large-instruct")
    p.add_argument("--k_ctx", type=int, default=5)
    p.add_argument("--k_in", type=int, default=50)
    p.add_argument("--k_dbg", type=int, default=10)
    p.add_argument("--llm_model", type=str, default="gpt-4o-mini")
    p.add_argument("--temperature", type=float, default=0.0)
    p.add_argument("--seed", type=int, default=42)
    p.add_argument("--out_dir", type=str, default="exp_outputs")
    p.add_argument("--exp_name", type=str, default="retriever_baseline")
    p.add_argument("--bm25_k1", type=float, default=1.5)
    p.add_argument("--bm25_b", type=float, default=0.75)
    p.add_argument("--hybrid_weights", type=float, nargs="*", default=None)
    args = p.parse_args()

    cfg = ExperimentConfig(
        embeddings_file=args.embeddings_file,
        index_version=args.index_version,
        retriever_id=args.retriever_id,
        embedding_model=args.embedding_model,
        k_ctx=args.k_ctx,
        k_in=args.k_in,
        k_dbg=args.k_dbg,
        llm_model=args.llm_model,
        temperature=args.temperature,
        seed=args.seed,
        out_dir=args.out_dir,
        exp_name=args.exp_name,
        bm25_k1=args.bm25_k1,
        bm25_b=args.bm25_b,
        hybrid_weights=args.hybrid_weights,
    )
    return cfg


def main():
    print("ğŸš€ ë²•ë¥  ë¬¸ì„œ RAG ë² ì´ìŠ¤ë¼ì¸ ì‹œì‘")
    cfg = build_config_from_args()
    print(f"â–¶ Config: {cfg}")

    try:
        rag = LegalRAGSystem(cfg)

        # 1) ë””ë²„ê¹…ìš© Retrieval í™•ì¸ (k_dbg)
        rag.test_similarity_search()
        rag.test_similarity_search_with_score()

        # 2) í›„ë³´êµ° ë¤í”„ (k_in) â€” ë¦¬ë­ì»¤íŒ€ ê³µí†µ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©
        q = "ì¢…í•©ë¶€ë™ì‚°ì„¸ ê³¼ì„¸í‘œì¤€ ë° ì„¸ìœ¨ì— ëŒ€í•´ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
        path, latency, top1 = rag.dump_candidates(q, k_in=cfg.k_in)
        # ê°„ë‹¨ ë¦¬í¬íŠ¸ CSV
        row = {
            "timestamp": now_kst_iso(),
            "exp_name": cfg.exp_name,
            "retriever_id": cfg.retriever_id,
            "index_version": cfg.index_version,
            "embedding_model": cfg.embedding_model,
            "k_in": cfg.k_in,
            "k_ctx": cfg.k_ctx,
            "query": q,
            "latency_s": round(latency, 4),
            "top1_score": round(top1, 6) if top1 is not None else None,
            "seed": cfg.seed,
        }
        csv_path = rag.write_report_row("retriever_report.csv", row)
        print(f"ğŸ§¾ ë¦¬í¬íŠ¸ ì—…ë°ì´íŠ¸: {csv_path}")

        # 3) ìŠ¤ëª¨í¬ ì§ˆë¬¸ ì‹¤í–‰ (k_ctx)
        rag.run_test_questions()

        # 4) ì„ íƒ: ì¸í„°ë™í‹°ë¸Œ
        try:
            user_input = input("\nğŸ¤” ëŒ€í™”í˜• ëª¨ë“œë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        except EOFError:
            user_input = "n"
        if user_input in ("y", "yes", "ì˜ˆ", "ã…‡"):
            print("\n=== ëŒ€í™”í˜• ëª¨ë“œ ===")
            while True:
                text = input("ì§ˆë¬¸(ì¢…ë£Œ:q): ").strip()
                if text.lower() in ("q", "quit", "exit", "ì¢…ë£Œ"):
                    break
                rag.ask_question(text)

        print("\nâœ… ì¢…ë£Œ")
    except FileNotFoundError:
        print("âŒ 'output_chunks_with_embeddings.json' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    except Exception as e:
        print(f"âŒ ì˜ˆì™¸ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
