import os
import json
import numpy as np
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv

# LangChain ì„í¬íŠ¸ (ìµœì‹  ë²„ì „)
from langchain_openai import ChatOpenAI
from langchain_core.documents import Document
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.vectorstores import VectorStore
from langchain_core.embeddings import Embeddings

# SentenceTransformer ì„í¬íŠ¸ (ê¸°ì¡´ ì„ë² ë”©ê³¼ ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš©)
from sentence_transformers import SentenceTransformer


class SentenceTransformerEmbeddings(Embeddings):
    """SentenceTransformerë¥¼ LangChain Embeddings ì¸í„°í˜ì´ìŠ¤ë¡œ ë˜í•‘"""
    
    def __init__(self, model_name: str = "intfloat/multilingual-e5-large-instruct"):
        self.model = SentenceTransformer(model_name)
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """ë¬¸ì„œë“¤ì„ ì„ë² ë”©í•©ë‹ˆë‹¤."""
        embeddings = self.model.encode(texts)
        return embeddings.tolist()
    
    def embed_query(self, text: str) -> List[float]:
        """ì¿¼ë¦¬ë¥¼ ì„ë² ë”©í•©ë‹ˆë‹¤."""
        # E5 ëª¨ë¸ì˜ ê²½ìš° ì¿¼ë¦¬ì— "query: " ì ‘ë‘ì‚¬ ì¶”ê°€
        query_text = f"query: {text}"
        embedding = self.model.encode(query_text)
        return embedding.tolist()


class NaiveVectorStore(VectorStore):
    """Naive VectorStore - LangChain í˜¸í™˜ ë²„ì „"""
    
    def __init__(self, documents: List[Document], embeddings: List[List[float]], embedding_function: Embeddings):
        self.documents = documents
        self._embeddings_matrix = np.array(embeddings, dtype=np.float32)
        self.embedding_function = embedding_function
        
        # ì„ë² ë”© ì •ê·œí™”
        self._embeddings_matrix = self._embeddings_matrix / np.linalg.norm(self._embeddings_matrix, axis=1, keepdims=True)
    
    def add_texts(self, texts: List[str], metadatas: Optional[List[dict]] = None, **kwargs) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€í•©ë‹ˆë‹¤."""
        raise NotImplementedError("add_textsëŠ” í˜„ì¬ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def similarity_search_by_vector(self, embedding: List[float], k: int = 4, **kwargs) -> List[Document]:
        """ë²¡í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        query_vector = np.array(embedding, dtype=np.float32)
        query_norm = query_vector / np.linalg.norm(query_vector)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = np.dot(self._embeddings_matrix, query_norm)
        
        # ìƒìœ„ kê°œ ì¸ë±ìŠ¤ ì¶”ì¶œ
        top_k_indices = similarities.argsort()[::-1][:k]
        
        return [self.documents[i] for i in top_k_indices]
    
    def similarity_search(self, query: str, k: int = 4, **kwargs) -> List[Document]:
        """ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        # ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        query_embedding = self.embedding_function.embed_query(query)
        return self.similarity_search_by_vector(query_embedding, k, **kwargs)
    
    def similarity_search_with_score(self, query: str, k: int = 4, **kwargs) -> List[tuple]:
        """ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        query_embedding = self.embedding_function.embed_query(query)
        query_vector = np.array(query_embedding, dtype=np.float32)
        query_norm = query_vector / np.linalg.norm(query_vector)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = np.dot(self._embeddings_matrix, query_norm)
        
        # ìƒìœ„ kê°œ ì¸ë±ìŠ¤ì™€ ì ìˆ˜ ì¶”ì¶œ
        top_k_indices = similarities.argsort()[::-1][:k]
        
        results = []
        for idx in top_k_indices:
            doc = self.documents[idx]
            score = float(similarities[idx])
            results.append((doc, score))
        
        return results
    
    @classmethod
    def from_texts(cls, texts: List[str], embedding: Embeddings, metadatas: Optional[List[dict]] = None, **kwargs):
        """í…ìŠ¤íŠ¸ë¡œë¶€í„° ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        raise NotImplementedError("from_textsëŠ” í˜„ì¬ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


class LegalRAGSystem:
    """ë²•ë¥  ë¬¸ì„œ RAG ì‹œìŠ¤í…œ í´ë˜ìŠ¤"""
    
    def __init__(self, embeddings_file: str = "output_chunks_with_embeddings.json"):
        """
        RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        
        Args:
            embeddings_file (str): ì„ë² ë”©ëœ ì²­í¬ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        """
        # íŒŒì¼ ê²½ë¡œë¥¼ ì ˆëŒ€ê²½ë¡œë¡œ ë³€í™˜ (í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
        if not os.path.isabs(embeddings_file):
            script_dir = os.path.dirname(os.path.abspath(__file__))
            self.embeddings_file = os.path.join(script_dir, embeddings_file)
        else:
            self.embeddings_file = embeddings_file
        self.documents = []
        self.vectorstore = None
        self.retriever = None
        self.rag_chain = None
        self.llm = None
        self.embedding_model = None
        
        # í™˜ê²½ ì„¤ì •
        self._setup_environment()
        
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_system()
    
    def _setup_environment(self):
        """í™˜ê²½ë³€ìˆ˜ ë° ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        load_dotenv()
        
        # LangSmith ì„¤ì • (ì„ íƒì )
        os.environ["LANGCHAIN_TRACING_V2"] = "true"
        os.environ["LANGCHAIN_ENDPOINT"] = os.getenv("LANGSMITH_ENDPOINT", "")
        os.environ["LANGCHAIN_API_KEY"] = os.getenv("LANGSMITH_API_KEY", "")
        
        print("âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ")
    
    def _load_embeddings_data(self) -> tuple:
        """ì„ë² ë”©ëœ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  Document ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        print(f"ğŸ“‚ ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì¤‘: {self.embeddings_file}")
        
        with open(self.embeddings_file, "r", encoding="utf-8") as f:
            chunk_data = json.load(f)
        
        documents = []
        embeddings_array = []
        
        for item in chunk_data:
            # LangChain Document ê°ì²´ ìƒì„±
            doc = Document(
                page_content=item["text"],
                metadata={
                    "filename": item["filename"],
                    "chunk_index": item["chunk_index"],
                    "source": f"{item['filename']}_chunk_{item['chunk_index']}"
                }
            )
            documents.append(doc)
            embeddings_array.append(item["embedding"])
        
        print(f"âœ… {len(documents)}ê°œì˜ ë¬¸ì„œ ì²­í¬ ë¡œë“œ ì™„ë£Œ")
        print(f"ğŸ“„ ì²« ë²ˆì§¸ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°: {documents[0].page_content[:100]}...")
        
        return documents, embeddings_array
    
    def _create_vectorstore(self, documents: List[Document], embeddings_array: List[List[float]]):
        """Naive VectorStoreë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        print("ğŸ”§ Naive VectorStore ìƒì„± ì¤‘...")
        
        # ê¸°ì¡´ ì„ë² ë”©ê³¼ ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš©
        self.embedding_model = SentenceTransformerEmbeddings()
        
        # Naive VectorStore ìƒì„±
        vectorstore = NaiveVectorStore(
            documents=documents,
            embeddings=embeddings_array,
            embedding_function=self.embedding_model
        )
        
        print(f"âœ… Naive VectorStore ìƒì„± ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: {len(documents)})")
        return vectorstore
    
    def _setup_rag_components(self):
        """RAG ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
        print("âš™ï¸ RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì¤‘...")
        
        # Retriever ìƒì„±(Naive Retriever)
        self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": 5})
        
        # ë²•ë¥  ë¬¸ì„œ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ìƒì„±
        legal_prompt = PromptTemplate.from_template(
            """ë‹¹ì‹ ì€ ë¶€ë™ì‚°ì„¸ë²• ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë²•ë¥  ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ğŸ“‹ **ì°¸ê³  ë¬¸ì„œ:**
{context}

ğŸ“ **ë‹µë³€ ì§€ì¹¨:**
1. ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì— ê·¼ê±°í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
2. ê´€ë ¨ ë²•ë ¹ ì¡°ë¬¸ì´ë‚˜ ì¡°í•­ì„ ëª…ì‹œí•´ì£¼ì„¸ìš”
3. ë²•ë¥ ì  ê·¼ê±°ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”
4. ë¬¸ì„œì—ì„œ ëª…í™•í•œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´ "ì œê³µëœ ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë§í•˜ì„¸ìš”
5. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”

â“ **ì§ˆë¬¸:** {question}

ğŸ’¡ **ë‹µë³€:**"""
        )
        
        # LLM ìƒì„±
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0,  # ì¼ê´€ëœ ë‹µë³€ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„ ì„¤ì •
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # Context í¬ë§·íŒ… í•¨ìˆ˜
        def format_docs(docs):
            """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
            formatted_docs = []
            for i, doc in enumerate(docs, 1):
                source = doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
                content = doc.page_content.strip()
                formatted_docs.append(f"ğŸ“„ **ë¬¸ì„œ {i}** ({source})\n{content}")
            return "\n\n" + "\n\n".join(formatted_docs) + "\n\n"
        
        # RAG ì²´ì¸ ìƒì„±
        self.rag_chain = (
            {
                "context": self.retriever | format_docs,
                "question": RunnablePassthrough()
            }
            | legal_prompt
            | self.llm
            | StrOutputParser()
        )
        
        print("âœ… RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì™„ë£Œ")
    
    def _initialize_system(self):
        """ì „ì²´ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        print("ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
        
        try:
            # ë°ì´í„° ë¡œë“œ
            self.documents, embeddings_array = self._load_embeddings_data()
            
            # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
            self.vectorstore = self._create_vectorstore(self.documents, embeddings_array)
            
            # RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì •
            self._setup_rag_components()
            
            print("ğŸ‰ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
            
        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def test_similarity_search(self, query: str = "ì¢…í•©ë¶€ë™ì‚°ì„¸ì˜ ëª©ì ", k: int = 10):
        """ìœ ì‚¬ë„ ê²€ìƒ‰ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
        print(f"\nğŸ” ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
        print(f"ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
        print(f"ê²€ìƒ‰ ê²°ê³¼ ({k}ê°œ):")
        print("-" * 50)
        
        if self.vectorstore is None:
            print("âŒ ë²¡í„°ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            similar_docs = self.vectorstore.similarity_search(query, k=k)
            
            for i, doc in enumerate(similar_docs, 1):
                print(f"[ê²°ê³¼ {i}] {doc.metadata['source']}")
                print(f"ë‚´ìš©: {doc.page_content[:150]}...")
                print("-" * 50)
            
            return similar_docs
            
        except Exception as e:
            print(f"âŒ ìœ ì‚¬ë„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
    
    def test_similarity_search_with_score(self, query: str = "ì¢…í•©ë¶€ë™ì‚°ì„¸ì˜ ëª©ì ", k: int = 10):
        """ì ìˆ˜ì™€ í•¨ê»˜ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
        print(f"\nğŸ” ì ìˆ˜ í¬í•¨ ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
        print(f"ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
        print(f"ê²€ìƒ‰ ê²°ê³¼ ({k}ê°œ):")
        print("-" * 50)
        
        if self.vectorstore is None:
            print("âŒ ë²¡í„°ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            results = self.vectorstore.similarity_search_with_score(query, k=k)
            
            for i, (doc, score) in enumerate(results, 1):
                print(f"[ê²°ê³¼ {i}] ìœ ì‚¬ë„: {score:.4f}")
                print(f"ì¶œì²˜: {doc.metadata['source']}")
                print(f"ë‚´ìš©: {doc.page_content[:150]}...")
                print("-" * 50)
            
            return results
            
        except Exception as e:
            print(f"âŒ ìœ ì‚¬ë„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
    
    def ask_question(self, question: str, show_sources: bool = True) -> str:
        """
        ë²•ë¥  ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            question (str): ë²•ë¥  ì§ˆë¬¸
            show_sources (bool): ì°¸ê³  ë¬¸ì„œ ì¶œì²˜ í‘œì‹œ ì—¬ë¶€
        
        Returns:
            str: ë‹µë³€
        """
        print(f"\nğŸ¤– ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘: {question}")
        print("-" * 50)
        
        try:
            # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ë° ì¶œì²˜ í‘œì‹œ
            if show_sources:
                relevant_docs = self.retriever.invoke(question)
                print("ğŸ“š **ì°¸ê³ í•œ ë¬¸ì„œ:**")
                for i, doc in enumerate(relevant_docs, 1):
                    source = doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    print(f"  {i}. {source}")
                print()
            
            # RAG ë‹µë³€ ìƒì„±
            response = self.rag_chain.invoke(question)
            
            print("ğŸ’¡ **ë‹µë³€:**")
            print(response)
            return response
            
        except Exception as e:
            error_msg = f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
            print(error_msg)
            return error_msg
    
    def run_test_questions(self):
        """ë¯¸ë¦¬ ì •ì˜ëœ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        test_questions = [
            "ì¢…í•©ë¶€ë™ì‚°ì„¸ë²•ì˜ ëª©ì ì„ ë²•ë ¹ ì¡°ë¬¸ì„ ê·¼ê±°ë¡œ í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "ì¢…í•©ë¶€ë™ì‚°ì„¸ ë‚©ì„¸ì˜ë¬´ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?",
            "ì¢…í•©ë¶€ë™ì‚°ì„¸ ê³¼ì„¸ëŒ€ìƒì€ ë¬´ì—‡ì¸ê°€ìš”?"
        ]
        
        print(f"\n{'='*60}")
        print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì‹¤í–‰")
        print(f"{'='*60}")
        
        for i, question in enumerate(test_questions, 1):
            print(f"\n{'='*60}")
            print(f"í…ŒìŠ¤íŠ¸ {i}: {question}")
            print(f"{'='*60}")
            
            try:
                self.ask_question(question)
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            
            print(f"\n{'-'*60}")


def interactive_mode(rag_system: LegalRAGSystem):
    """ëŒ€í™”í˜• ëª¨ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    print(f"\n{'='*60}")
    print("ğŸ¤– ë²•ë¥  ë¬¸ì„œ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ - ëŒ€í™”í˜• ëª¨ë“œ")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit', 'exit', ë˜ëŠ” 'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    print(f"{'='*60}")
    
    while True:
        try:
            question = input("\nâ“ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            if question.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
                print("ğŸ‘‹ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            if not question:
                print("âš ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue
            
            rag_system.ask_question(question)
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ë²•ë¥  ë¬¸ì„œ RAG ì‹œìŠ¤í…œ ì‹œì‘")
    print("=" * 60)
    
    try:
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        rag_system = LegalRAGSystem()
        
        # ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        rag_system.test_similarity_search()
        
        # ì ìˆ˜ í¬í•¨ ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        rag_system.test_similarity_search_with_score()
        
        # ë¯¸ë¦¬ ì •ì˜ëœ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì‹¤í–‰
        rag_system.run_test_questions()
        
        # ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰ (ì„ íƒì )
        user_input = input("\nğŸ¤” ëŒ€í™”í˜• ëª¨ë“œë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        if user_input in ['y', 'yes', 'ì˜ˆ', 'ã…‡']:
            interactive_mode(rag_system)
        
        print("\nâœ… í”„ë¡œê·¸ë¨ì´ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except FileNotFoundError:
        print("âŒ ì˜¤ë¥˜: 'output_chunks_with_embeddings.json' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ“ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ì„ë² ë”© íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


if __name__ == "__main__":
    main()