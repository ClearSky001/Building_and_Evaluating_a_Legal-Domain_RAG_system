import sys
import os
from pathlib import Path
from typing import List, Optional, Dict

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ fixed_base_v2 ëª¨ë“ˆ import
current_dir = Path(__file__).parent
parent_dir = current_dir.parent
sys.path.insert(0, str(parent_dir))

from fixed_base_v2 import (
    SentenceTransformerEmbeddings,
    NaiveVectorStore,
    BaseReranker,
    BaseDocumentCompressor,
    SimpleCompressionRetriever,
    load_embeddings_data,
    setup_environment,
    create_legal_prompt,
    format_docs,
    get_embeddings_file_path,
    _tokenize_ko
)

from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.documents import Document
from rank_bm25 import BM25Okapi
import numpy as np


class CombSumCompressor(BaseDocumentCompressor):
    """CombSum ë°©ì‹ì˜ í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ë­ì»¤"""
    def __init__(self, top_n: int = 10):
        super().__init__()
        self.top_n = top_n
        self.embed_model = SentenceTransformerEmbeddings()

    def compress_documents(self, documents: list[Document], query: str, callbacks=None) -> list[Document]:
        if not documents:
            return []
        
        # BM25 ì ìˆ˜ ê³„ì‚°
        corpus_tokens = [_tokenize_ko(doc.page_content) for doc in documents]
        bm25 = BM25Okapi(corpus_tokens)
        query_tokens = _tokenize_ko(query)
        bm25_scores = bm25.get_scores(query_tokens)
        
        # ì„ë² ë”© ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
        q_emb = np.array(self.embed_model.embed_query(query), dtype=np.float32)
        doc_embs = np.array(self.embed_model.embed_documents([d.page_content for d in documents]), dtype=np.float32)
        embed_scores = np.dot(doc_embs, q_emb)
        
        # ì ìˆ˜ ì •ê·œí™” (0-1 ë²”ìœ„)
        bm25_scores = (bm25_scores - bm25_scores.min()) / (bm25_scores.max() - bm25_scores.min() + 1e-8)
        embed_scores = (embed_scores - embed_scores.min()) / (embed_scores.max() - embed_scores.min() + 1e-8)
        
        # CombSum: ë‘ ì ìˆ˜ë¥¼ í•©ì‚°
        combined_scores = bm25_scores + embed_scores
        
        # ìƒìœ„ Nê°œ ì„ íƒ
        order = combined_scores.argsort()[::-1][:self.top_n]
        return [documents[i] for i in order]


class LegalRAGSystemCombSum:
    def __init__(self, embeddings_file: str = "output_chunks_with_embeddings.json", base_k: int = 100, rerank_top_n: int = 12):
        # ì„ë² ë”© íŒŒì¼ ê²½ë¡œ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •
        self.embeddings_file = get_embeddings_file_path(__file__, embeddings_file)
        self.base_k = base_k
        self.rerank_top_n = rerank_top_n
        
        self.documents = []
        self.vectorstore = None
        self.retriever = None
        self.rag_chain = None
        self.llm = None
        self.embedding_model = None
        self.reranker = None

        self._setup_environment()
        self._initialize_system()

    def _setup_environment(self):
        setup_environment()

    def _load_embeddings_data(self) -> tuple:
        return load_embeddings_data(self.embeddings_file)

    def _create_vectorstore(self, documents, embeddings_array):
        print("ğŸ”§ Naive VectorStore ìƒì„± ì¤‘...")
        self.embedding_model = SentenceTransformerEmbeddings()
        vectorstore = NaiveVectorStore(
            documents=documents,
            embeddings=embeddings_array,
            embedding_function=self.embedding_model
        )
        print(f"âœ… Naive VectorStore ìƒì„± ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: {len(documents)})")
        return vectorstore

    def _setup_rag_components(self):
        print("âš™ï¸ RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì¤‘ (CombSum Hybrid Re-ranker) ...")
        
        # ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
        base_retriever = self.vectorstore.as_retriever(search_kwargs={"k": self.base_k})
        
        # CombSum ë¦¬ë­ì»¤ ìƒì„±
        self.reranker = CombSumCompressor(top_n=self.rerank_top_n)
        
        # ì••ì¶• ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
        self.retriever = SimpleCompressionRetriever(base_retriever, self.reranker)

        # í”„ë¡¬í”„íŠ¸ ë° LLM ì„¤ì •
        legal_prompt = create_legal_prompt()
        
        self.llm = ChatOpenAI(
            model="gpt-4o",
            temperature=0,
            openai_api_key=os.getenv("OPENAI_API_KEY"),
        )

        # RAG ì²´ì¸ ì„¤ì •
        def get_context(question):
            docs = self.retriever.invoke(question)
            return format_docs(docs)
        
        self.rag_chain = (
            {
                "context": get_context,
                "question": RunnablePassthrough(),
            }
            | legal_prompt
            | self.llm
            | StrOutputParser()
        )
        print("âœ… RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì™„ë£Œ")

    def _initialize_system(self):
        print("ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
        try:
            self.documents, embeddings_array = self._load_embeddings_data()
            self.vectorstore = self._create_vectorstore(self.documents, embeddings_array)
            self._setup_rag_components()
            print("ğŸ‰ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise

    def rerank_documents(
        self,
        query: str,
        candidate_documents: Optional[List[dict]] = None,
        model: str = "Hybrid-CombSum"
    ) -> dict:
        """
        ìƒˆë¡œìš´ í‘œì¤€ ì¸í„°í˜ì´ìŠ¤ - ë¦¬ë­í‚¹ë§Œ ìˆ˜í–‰
        
        Args:
            query (str): ì‚¬ìš©ì ì§ˆë¬¸/ê²€ìƒ‰ì–´
            candidate_documents (Optional[List[dict]]): í›„ë³´ ë¬¸ì„œë“¤
            model (str): ë¦¬ë­ì»¤ ëª¨ë¸/ë°©ì‹ (í…ŒìŠ¤íŠ¸ìš©)
            
        Returns:
            dict: {'retrieved_docs': [{'doc_id': str, 'chunk_index': int, 'score': float, 'filename': str, 'text': str}, ...]}
        """
        if candidate_documents is None:
            # í›„ë³´ ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê²€ìƒ‰ ìˆ˜í–‰
            base_retriever = self.vectorstore.as_retriever(search_kwargs={"k": self.base_k})
            candidate_docs = base_retriever.invoke(query)
            # Document ê°ì²´ë¥¼ dict í˜•íƒœë¡œ ë³€í™˜
            candidate_documents = []
            for i, doc in enumerate(candidate_docs):
                doc_dict = {
                    'doc_id': f"doc_{i}",
                    'chunk_index': i,
                    'score': 1.0,
                    'filename': doc.metadata.get('source', 'unknown'),
                    'text': doc.page_content
                }
                candidate_documents.append(doc_dict)
        
        # CombSum ë¦¬ë­í‚¹ ìˆ˜í–‰
        docs_to_rerank = [Document(page_content=doc['text'], metadata={'source': doc['filename']}) for doc in candidate_documents]
        reranked_docs = self.reranker.compress_documents(docs_to_rerank, query)
        
        # ê²°ê³¼ë¥¼ dict í˜•íƒœë¡œ ë³€í™˜
        result_docs = []
        for i, doc in enumerate(reranked_docs):
            doc_dict = {
                'doc_id': f"reranked_{i}",
                'chunk_index': i,
                'score': 1.0 - (i * 0.1),  # ìˆœì„œì— ë”°ë¥¸ ì ìˆ˜
                'filename': doc.metadata.get('source', 'unknown'),
                'text': doc.page_content
            }
            result_docs.append(doc_dict)
        
        return {'retrieved_docs': result_docs}

    def search(self, query: str, k: int = 10) -> List[Document]:
        """ê²€ìƒ‰ + ë¦¬ë­í‚¹ì„ í•¨ê»˜ ìˆ˜í–‰í•˜ëŠ” ë©”ì„œë“œ"""
        try:
            # 1. ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ ë” ë§ì€ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜´
            base_retriever = self.vectorstore.as_retriever(search_kwargs={"k": self.base_k})
            initial_docs = base_retriever.invoke(query)
            
            if not initial_docs:
                return []
            
            # 2. Hybrid CombSumìœ¼ë¡œ ë¦¬ë­í‚¹ ìˆ˜í–‰ (ì‹¤ì œë¡œ ìˆœì„œë¥¼ ë°”ê¿ˆ)
            # ì´ˆê¸° ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ Hybrid CombSumìœ¼ë¡œ ì¬ì •ë ¬
            reranked_docs = self.retriever.reranker.compress_documents(initial_docs, query)
            
            return reranked_docs[:k] if reranked_docs else []
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []

    def search_and_rerank(self, query: str) -> dict:
        """ê²€ìƒ‰ + ë¦¬ë­í‚¹ì„ í•¨ê»˜ ìˆ˜í–‰í•˜ëŠ” ë©”ì„œë“œ"""
        return self.rerank_documents(query)

    def ask_question(self, question: str, show_sources: bool = True) -> str:
        print(f"\nğŸ¤– ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘: {question}")
        print("-" * 50)
        try:
            if show_sources:
                # ìƒˆë¡œìš´ ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©
                result = self.search_and_rerank(question)
                retrieved_docs = result['retrieved_docs']
                
                print("ğŸ“š **ì°¸ê³ í•œ ë¬¸ì„œ:**")
                for i, doc_info in enumerate(retrieved_docs, 1):
                    print(f"  {i}. {doc_info['doc_id']} (ì ìˆ˜: {doc_info['score']:.4f})")
                print()
                
            # OpenAI API í‚¤ê°€ ì—†ìœ¼ë©´ ê²€ìƒ‰ë§Œ ìˆ˜í–‰
            if not os.getenv("OPENAI_API_KEY"):
                return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ê²€ìƒ‰ë§Œ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤."
            
            response = self.rag_chain.invoke(question)
            print("ğŸ’¡ **ë‹µë³€:**")
            print(response)
            return response
        except Exception as e:
            error_msg = f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
            print(error_msg)
            return error_msg


def main():
    print("ğŸš€ ë²•ë¥  ë¬¸ì„œ RAG ì‹œìŠ¤í…œ (CombSum Hybrid Re-ranker) ì‹œì‘")
    print("=" * 60)
    try:
        rag_system = LegalRAGSystemCombSum()
        rag_system.ask_question("ì¢…í•©ë¶€ë™ì‚°ì„¸ë²•ì˜ ëª©ì ì„ ë²•ë ¹ ì¡°ë¬¸ì„ ê·¼ê±°ë¡œ í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
        print("\nâœ… í”„ë¡œê·¸ë¨ì´ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


if __name__ == "__main__":
    main()
