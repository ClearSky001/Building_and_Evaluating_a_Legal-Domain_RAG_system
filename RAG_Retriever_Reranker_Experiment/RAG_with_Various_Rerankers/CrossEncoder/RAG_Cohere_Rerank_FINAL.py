import sys
import os
import time
from pathlib import Path

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ fixed_base ëª¨ë“ˆ import
current_dir = Path(__file__).parent
parent_dir = current_dir.parent
sys.path.insert(0, str(parent_dir))

from fixed_base_v2 import (
    SentenceTransformerEmbeddings,
    NaiveVectorStore,
    BaseDocumentCompressor,
    BaseReranker,
    SimpleCompressionRetriever,
    load_embeddings_data,
    setup_environment,
    create_legal_prompt,
    format_docs,
    get_embeddings_file_path
)

from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.documents import Document


class CohereRerank(BaseReranker):
    """ì‹¤ì œ Cohere APIë¥¼ ì‚¬ìš©í•˜ëŠ” ë¦¬ë­ì»¤"""
    def __init__(self, top_n: int = 10):
        super().__init__(top_n)
        # Rate limiting ë³€ìˆ˜ë“¤
        self.last_call_time = 0
        self.call_count = 0
        self.rate_limit_delay = 7  # 7ì´ˆ ëŒ€ê¸° (Trial: 10 calls/minute)
        
        try:
            import cohere
            # .env íŒŒì¼ ë¡œë“œ
            from dotenv import load_dotenv
            load_dotenv()
            
            # Cohere API í‚¤ í™•ì¸
            cohere_api_key = os.getenv("COHERE_API_KEY")
            if not cohere_api_key:
                print("âš ï¸ COHERE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CrossEncoderë¥¼ ëŒ€ì‹  ì‚¬ìš©í•©ë‹ˆë‹¤.")
                from sentence_transformers import CrossEncoder
                self.model = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")
                self.use_cohere = False
            else:
                print(f"âœ… Cohere API í‚¤ í™•ì¸ë¨: {cohere_api_key[:10]}...")
                self.co = cohere.Client(cohere_api_key)
                self.use_cohere = True
                # Cohere ì‚¬ìš© ì‹œì—ë„ model ì†ì„± ì¶”ê°€ (fallbackìš©)
                from sentence_transformers import CrossEncoder
                self.model = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")
        except ImportError:
            print("âš ï¸ cohere íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CrossEncoderë¥¼ ëŒ€ì‹  ì‚¬ìš©í•©ë‹ˆë‹¤.")
            from sentence_transformers import CrossEncoder
            self.model = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")
            self.use_cohere = False

    def _rate_limit_check(self):
        """Rate limiting ì²´í¬ ë° ëŒ€ê¸°"""
        current_time = time.time()
        
        # ì²« ë²ˆì§¸ í˜¸ì¶œì´ê±°ë‚˜ 1ë¶„ì´ ì§€ë‚¬ìœ¼ë©´ ì¹´ìš´í„° ë¦¬ì…‹
        if current_time - self.last_call_time > 60:
            self.call_count = 0
        
        # 10ë²ˆ í˜¸ì¶œí–ˆìœ¼ë©´ 7ì´ˆ ëŒ€ê¸°
        if self.call_count >= 10:
            wait_time = self.rate_limit_delay - (current_time - self.last_call_time)
            if wait_time > 0:
                print(f"â³ Cohere API Rate Limit ë„ë‹¬. {wait_time:.1f}ì´ˆ ëŒ€ê¸° ì¤‘...")
                time.sleep(wait_time)
            self.call_count = 0
        
        self.last_call_time = current_time
        self.call_count += 1

    def rerank_documents(self, query: str, candidate_documents=None, **kwargs):
        """ìƒˆë¡œìš´ í‘œì¤€ ì¸í„°í˜ì´ìŠ¤ - rerank_documents ë©”ì„œë“œ"""
        if not candidate_documents:
            return {'retrieved_docs': []}
        
        try:
            if self.use_cohere:
                # Rate limiting ì²´í¬
                self._rate_limit_check()
                
                # Cohere rerank API ì‚¬ìš©
                texts = [doc['text'] for doc in candidate_documents]
                response = self.co.rerank(
                    model="rerank-multilingual-v3.0",
                    query=query,
                    documents=texts,
                    top_n=self.top_n
                )
                
                # Cohere ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì„œ ì •ë ¬
                reranked_docs = []
                for result in response.results:
                    original_doc = candidate_documents[result.index]
                    reranked_docs.append({
                        'doc_id': original_doc['doc_id'],
                        'chunk_index': original_doc['chunk_index'],
                        'filename': original_doc['filename'],
                        'text': original_doc['text'],
                        'score': result.relevance_score
                    })
                
                return {'retrieved_docs': reranked_docs}
            else:
                # CrossEncoder fallback
                pairs = [[query, doc['text']] for doc in candidate_documents]
                scores = self.model.predict(pairs)
                
                # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
                doc_scores = list(zip(candidate_documents, scores))
                doc_scores.sort(key=lambda x: x[1], reverse=True)
                
                reranked_docs = []
                for doc, score in doc_scores[:self.top_n]:
                    reranked_docs.append({
                        'doc_id': doc['doc_id'],
                        'chunk_index': doc['chunk_index'],
                        'filename': doc['filename'],
                        'text': doc['text'],
                        'score': float(score)
                    })
                
                return {'retrieved_docs': reranked_docs}
                
        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg or "rate limit" in error_msg.lower():
                print(f"âš ï¸ Cohere API Rate Limit ë„ë‹¬. CrossEncoderë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                # CrossEncoderë¡œ fallback
                pairs = [[query, doc['text']] for doc in candidate_documents]
                scores = self.model.predict(pairs)
                
                # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
                doc_scores = list(zip(candidate_documents, scores))
                doc_scores.sort(key=lambda x: x[1], reverse=True)
                
                reranked_docs = []
                for doc, score in doc_scores[:self.top_n]:
                    reranked_docs.append({
                        'doc_id': doc['doc_id'],
                        'chunk_index': doc['chunk_index'],
                        'filename': doc['filename'],
                        'text': doc['text'],
                        'score': float(score)
                    })
                
                return {'retrieved_docs': reranked_docs}
            else:
                print(f"âš ï¸ ë¦¬ë­í‚¹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                return {'retrieved_docs': candidate_documents[:self.top_n]}

    def compress_documents(self, documents: list[Document], query: str, callbacks=None) -> list[Document]:
        """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ compress_documents ë©”ì„œë“œ"""
        if not documents:
            return []
        
        # Documentë¥¼ dict í˜•íƒœë¡œ ë³€í™˜
        candidate_docs = []
        for i, doc in enumerate(documents):
            candidate_docs.append({
                'doc_id': f'doc_{i}',
                'chunk_index': i,
                'filename': doc.metadata.get('source', 'unknown'),
                'text': doc.page_content,
                'score': 0.0
            })
        
        # rerank_documents í˜¸ì¶œ
        result = self.rerank_documents(query, candidate_docs)
        
        # Document í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        reranked_docs = []
        for doc_info in result['retrieved_docs']:
            doc = Document(
                page_content=doc_info['text'],
                metadata={
                    'source': doc_info['filename'],
                    'chunk_index': doc_info['chunk_index'],
                    'score': doc_info['score']
                }
            )
            reranked_docs.append(doc)
        
        return reranked_docs


class LegalRAGSystemCohereRerank:
    def __init__(self, embeddings_file: str = "output_chunks_with_embeddings.json", base_k: int = 80, rerank_top_n: int = 10):
        # ì„ë² ë”© íŒŒì¼ ê²½ë¡œ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •
        self.embeddings_file = get_embeddings_file_path(__file__, embeddings_file)
        self.base_k = base_k
        self.rerank_top_n = rerank_top_n
        
        self.documents = []
        self.vectorstore = None
        self.retriever = None
        self.rag_chain = None
        self.llm = None
        self.embedding_model = None

        self._setup_environment()
        self._initialize_system()

    def _setup_environment(self):
        setup_environment()

    def _load_embeddings_data(self) -> tuple:
        return load_embeddings_data(self.embeddings_file)

    def _create_vectorstore(self, documents, embeddings_array):
        print("ğŸ”§ Naive VectorStore ìƒì„± ì¤‘...")
        # Cohere ë¦¬ë­ì»¤ëŠ” ê¸°ë³¸ E5 ëª¨ë¸ ì‚¬ìš© (ê³µì •í•œ ë¹„êµë¥¼ ìœ„í•´)
        self.embedding_model = SentenceTransformerEmbeddings()
        vectorstore = NaiveVectorStore(
            documents=documents,
            embeddings=embeddings_array,
            embedding_function=self.embedding_model
        )
        print(f"âœ… Naive VectorStore ìƒì„± ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: {len(documents)})")
        return vectorstore

    def _setup_rag_components(self):
        print("âš™ï¸ RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì¤‘ (Cohere Reranker) ...")
        
        # ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
        base_retriever = self.vectorstore.as_retriever(search_kwargs={"k": self.base_k})
        
        # Cohere ì••ì¶•ê¸° ìƒì„±
        compressor = CohereRerank(top_n=self.rerank_top_n)
        
        # ì••ì¶• ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
        self.retriever = SimpleCompressionRetriever(base_retriever, compressor)

        # í”„ë¡¬í”„íŠ¸ ë° LLM ì„¤ì •
        legal_prompt = create_legal_prompt()
        
        self.llm = ChatOpenAI(
            model="gpt-4o",
            temperature=0,
            openai_api_key=os.getenv("OPENAI_API_KEY"),
        )

        # RAG ì²´ì¸ ì„¤ì •
        def get_context(question):
            docs = self.retriever.invoke(question)
            return format_docs(docs)
        
        self.rag_chain = (
            {
                "context": get_context,
                "question": RunnablePassthrough(),
            }
            | legal_prompt
            | self.llm
            | StrOutputParser()
        )
        print("âœ… RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì™„ë£Œ")

    def _initialize_system(self):
        print("ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
        try:
            self.documents, embeddings_array = self._load_embeddings_data()
            self.vectorstore = self._create_vectorstore(self.documents, embeddings_array)
            self._setup_rag_components()
            print("ğŸ‰ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise

    def search(self, query: str, k: int = 10):
        """ê²€ìƒ‰ + ë¦¬ë­í‚¹ì„ í•¨ê»˜ ìˆ˜í–‰í•˜ëŠ” ë©”ì„œë“œ"""
        try:
            # 1. ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ ë” ë§ì€ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜´
            base_retriever = self.vectorstore.as_retriever(search_kwargs={"k": self.base_k})
            initial_docs = base_retriever.invoke(query)
            
            if not initial_docs:
                return []
            
            # 2. Cohereë¡œ ë¦¬ë­í‚¹ ìˆ˜í–‰ (ì‹¤ì œë¡œ ìˆœì„œë¥¼ ë°”ê¿ˆ)
            # ì´ˆê¸° ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ Cohereë¡œ ì¬ì •ë ¬
            reranked_docs = self.retriever.reranker.compress_documents(initial_docs, query)
            
            return reranked_docs[:k] if reranked_docs else []
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []

    def ask_question(self, question: str, show_sources: bool = True) -> str:
        print(f"\nğŸ¤– ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘: {question}")
        print("-" * 50)
        try:
            if show_sources:
                relevant_docs = self.retriever.invoke(question)
                print("ğŸ“š **ì°¸ê³ í•œ ë¬¸ì„œ:**")
                for i, doc in enumerate(relevant_docs, 1):
                    source = doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    print(f"  {i}. {source}")
                print()
                
            # OpenAI API í‚¤ê°€ ì—†ìœ¼ë©´ ê²€ìƒ‰ë§Œ ìˆ˜í–‰
            if not os.getenv("OPENAI_API_KEY"):
                return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ê²€ìƒ‰ë§Œ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤."
            
            response = self.rag_chain.invoke(question)
            print("ğŸ’¡ **ë‹µë³€:**")
            print(response)
            return response
        except Exception as e:
            error_msg = f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
            print(error_msg)
            return error_msg


def main():
    print("ğŸš€ ë²•ë¥  ë¬¸ì„œ RAG ì‹œìŠ¤í…œ (Cohere Reranker) ì‹œì‘")
    print("=" * 60)
    print("ğŸ“ Cohere API ì‚¬ìš©ì„ ìœ„í•´ì„œëŠ” ë‹¤ìŒì´ í•„ìš”í•©ë‹ˆë‹¤:")
    print("   1. pip install cohere")
    print("   2. COHERE_API_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì •")
    print("   3. API í‚¤ê°€ ì—†ìœ¼ë©´ CrossEncoderë¥¼ ëŒ€ì‹  ì‚¬ìš©í•©ë‹ˆë‹¤.")
    print("=" * 60)
    try:
        rag_system = LegalRAGSystemCohereRerank()
        rag_system.ask_question("ì¢…í•©ë¶€ë™ì‚°ì„¸ë²•ì˜ ëª©ì ì„ ë²•ë ¹ ì¡°ë¬¸ì„ ê·¼ê±°ë¡œ í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
        print("\nâœ… í”„ë¡œê·¸ë¨ì´ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


if __name__ == "__main__":
    main()
