#!/usr/bin/env python3
"""
ë‚˜ë¨¸ì§€ FINAL íŒŒì¼ë“¤ì„ ìë™ ìƒì„±í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
from pathlib import Path

def create_final_file(file_path: str, class_name: str, description: str, model_name: str = None, reranker_type: str = "SentenceTransformerRerank"):
    """FINAL íŒŒì¼ í…œí”Œë¦¿ ìƒì„±"""
    
    # ê²½ë¡œ ì„¤ì • ë¶€ë¶„
    if "BGE ê³„ì—´" in file_path:
        path_setup = '''# ì„ë² ë”© íŒŒì¼ ê²½ë¡œ ì˜¬ë°”ë¥´ê²Œ ì„¤ì • (BGE ê³„ì—´ì€ 2ë‹¨ê³„ ìƒìœ„)
        if not os.path.isabs(embeddings_file):
            script_dir = os.path.dirname(os.path.abspath(__file__))
            self.embeddings_file = os.path.join(script_dir, "..", "..", "..", "output_chunks_with_embeddings.json")
            self.embeddings_file = os.path.normpath(self.embeddings_file)
        else:
            self.embeddings_file = embeddings_file'''
    else:
        path_setup = '''# ì„ë² ë”© íŒŒì¼ ê²½ë¡œ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •
        self.embeddings_file = get_embeddings_file_path(__file__, embeddings_file)'''
    
    # ë¦¬ë­ì»¤ ì„¤ì • ë¶€ë¶„
    if reranker_type == "SentenceTransformerRerank":
        reranker_setup = f'''        # {description} ì••ì¶•ê¸° ìƒì„±
        compressor = SentenceTransformerRerank(
            model_name="{model_name}",
            top_n=self.rerank_top_n,
        )'''
    else:
        reranker_setup = f'''        # {description} ì••ì¶•ê¸° ìƒì„±
        compressor = {reranker_type}(top_n=self.rerank_top_n)'''
    
    content = f'''"""
ì™„ì „íˆ ìˆ˜ì •ëœ {description} ë¦¬ë­ì»¤ - ëª¨ë“  ë¬¸ì œ í•´ê²°
"""
import sys
import os
from pathlib import Path

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ fixed_base ëª¨ë“ˆ import
current_dir = Path(__file__).parent
parent_dir = current_dir.parent
sys.path.insert(0, str(parent_dir))

from fixed_base import (
    SentenceTransformerEmbeddings,
    NaiveVectorStore,
    BaseDocumentCompressor,
    SimpleCompressionRetriever,
    load_embeddings_data,
    setup_environment,
    create_legal_prompt,
    format_docs,
    get_embeddings_file_path,
    SentenceTransformerRerank
)

from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough


class {class_name}:
    def __init__(self, embeddings_file: str = "output_chunks_with_embeddings.json", base_k: int = 80, rerank_top_n: int = 10):
        {path_setup}
        self.base_k = base_k
        self.rerank_top_n = rerank_top_n
        
        self.documents = []
        self.vectorstore = None
        self.retriever = None
        self.rag_chain = None
        self.llm = None
        self.embedding_model = None

        self._setup_environment()
        self._initialize_system()

    def _setup_environment(self):
        setup_environment()

    def _load_embeddings_data(self) -> tuple:
        return load_embeddings_data(self.embeddings_file)

    def _create_vectorstore(self, documents, embeddings_array):
        print("ğŸ”§ Naive VectorStore ìƒì„± ì¤‘...")
        self.embedding_model = SentenceTransformerEmbeddings()
        vectorstore = NaiveVectorStore(
            documents=documents,
            embeddings=embeddings_array,
            embedding_function=self.embedding_model
        )
        print(f"âœ… Naive VectorStore ìƒì„± ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: {{len(documents)}})")
        return vectorstore

    def _setup_rag_components(self):
        print("âš™ï¸ RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì¤‘ ({description} Re-ranker) ...")
        
        # ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
        base_retriever = self.vectorstore.as_retriever(search_kwargs={{"k": self.base_k}})
        
{reranker_setup}
        
        # ì••ì¶• ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
        self.retriever = SimpleCompressionRetriever(base_retriever, compressor)

        # í”„ë¡¬í”„íŠ¸ ë° LLM ì„¤ì •
        legal_prompt = create_legal_prompt()
        
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0,
            openai_api_key=os.getenv("OPENAI_API_KEY"),
        )

        # RAG ì²´ì¸ ì„¤ì •
        def get_context(question):
            docs = self.retriever.invoke(question)
            return format_docs(docs)
        
        self.rag_chain = (
            {{
                "context": get_context,
                "question": RunnablePassthrough(),
            }}
            | legal_prompt
            | self.llm
            | StrOutputParser()
        )
        print("âœ… RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì™„ë£Œ")

    def _initialize_system(self):
        print("ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
        try:
            self.documents, embeddings_array = self._load_embeddings_data()
            self.vectorstore = self._create_vectorstore(self.documents, embeddings_array)
            self._setup_rag_components()
            print("ğŸ‰ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {{e}}")
            raise

    def ask_question(self, question: str, show_sources: bool = True) -> str:
        print(f"\\nğŸ¤– ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘: {{question}}")
        print("-" * 50)
        try:
            if show_sources:
                relevant_docs = self.retriever.invoke(question)
                print("ğŸ“š **ì°¸ê³ í•œ ë¬¸ì„œ:**")
                for i, doc in enumerate(relevant_docs, 1):
                    source = doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    print(f"  {{i}}. {{source}}")
                print()
                
            # OpenAI API í‚¤ê°€ ì—†ìœ¼ë©´ ê²€ìƒ‰ë§Œ ìˆ˜í–‰
            if not os.getenv("OPENAI_API_KEY"):
                return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ê²€ìƒ‰ë§Œ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤."
            
            response = self.rag_chain.invoke(question)
            print("ğŸ’¡ **ë‹µë³€:**")
            print(response)
            return response
        except Exception as e:
            error_msg = f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {{e}}"
            print(error_msg)
            return error_msg


def main():
    print("ğŸš€ ë²•ë¥  ë¬¸ì„œ RAG ì‹œìŠ¤í…œ ({description} Re-ranker) ì‹œì‘")
    print("=" * 60)
    try:
        rag_system = {class_name}()
        rag_system.ask_question("ì¢…í•©ë¶€ë™ì‚°ì„¸ë²•ì˜ ëª©ì ì„ ë²•ë ¹ ì¡°ë¬¸ì„ ê·¼ê±°ë¡œ í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
        print("\\nâœ… í”„ë¡œê·¸ë¨ì´ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {{e}}")


if __name__ == "__main__":
    main()'''
    
    return content

# íŒŒì¼ ì •ì˜ë“¤
files_to_create = [
    # CrossEncoder ë‚˜ë¨¸ì§€ë“¤
    ("CrossEncoder/RAG_Jina_v2_Base_Multilingual_Rerank_FINAL.py", "LegalRAGSystemJinaV2Base", "Jina v2 Base Multilingual", "jinaai/jina-reranker-v2-base-multilingual"),
    ("CrossEncoder/RAG_MXBAI_Rerank_FINAL.py", "LegalRAGSystemMXBAI", "MXBAI", "mixedbread-ai/mxbai-rerank-large-v1"),
    
    # BGE ê³„ì—´ ë‚˜ë¨¸ì§€ë“¤
    ("CrossEncoder/BGE ê³„ì—´/RAG_BGE_Large_Rerank_FINAL.py", "LegalRAGSystemBGELarge", "BGE Large", "BAAI/bge-reranker-large"),
    ("CrossEncoder/BGE ê³„ì—´/RAG_BGE_v2m3_Rerank_FINAL.py", "LegalRAGSystemBGEV2M3", "BGE v2 M3", "BAAI/bge-reranker-v2-m3"),
    
    # Embedding ë‚˜ë¨¸ì§€ë“¤  
    ("Embedding_Reranker/RAG_EmbeddingCosine_MPNet_Rerank_FINAL.py", "LegalRAGSystemEmbeddingMPNet", "Embedding MPNet", "sentence-transformers/all-mpnet-base-v2"),
    ("Embedding_Reranker/RAG_EmbeddingCosine_Stella_Rerank_FINAL.py", "LegalRAGSystemEmbeddingStella", "Embedding Stella", "InfReality/stellarmind-ko-base-v1"),
]

base_dir = Path(__file__).parent

for file_path, class_name, description, model_name in files_to_create:
    full_path = base_dir / file_path
    full_path.parent.mkdir(parents=True, exist_ok=True)
    
    content = create_final_file(file_path, class_name, description, model_name)
    
    with open(full_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"âœ… ìƒì„± ì™„ë£Œ: {file_path}")

print("\nğŸ‰ ëª¨ë“  FINAL íŒŒì¼ ìƒì„± ì™„ë£Œ!")
