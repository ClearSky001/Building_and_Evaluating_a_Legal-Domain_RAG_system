#!/usr/bin/env python3
"""
ëª¨ë“  FINAL íŒŒì¼ë“¤ì„ ìƒˆë¡œìš´ V2 ì¸í„°í˜ì´ìŠ¤ë¡œ ìë™ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
import os
import re
from pathlib import Path
from typing import Dict, List

def get_reranker_info(file_path: Path) -> Dict:
    """íŒŒì¼ ê²½ë¡œì—ì„œ ë¦¬ë­ì»¤ ì •ë³´ ì¶”ì¶œ"""
    file_name = file_path.stem
    
    # ë¦¬ë­ì»¤ íƒ€ì…ë³„ ì •ë³´ ë§¤í•‘
    reranker_mappings = {
        # BM25 ê³„ì—´
        "RAG_BM25_Rerank_FINAL": {
            "reranker_class": "BM25Reranker",
            "description": "BM25 ê¸°ë³¸",
            "model_name": "BM25"
        },
        "RAG_BM25_CharNgram_Rerank_FINAL": {
            "reranker_class": "BM25CharNgramReranker", 
            "description": "BM25 CharNgram",
            "model_name": "BM25-CharNgram"
        },
        "RAG_BM25_Kiwi_Rerank_FINAL": {
            "reranker_class": "BM25KiwiReranker",
            "description": "BM25 Kiwi", 
            "model_name": "BM25-Kiwi"
        },
        "RAG_BM25_Regex_Rerank_FINAL": {
            "reranker_class": "BM25RegexReranker",
            "description": "BM25 Regex",
            "model_name": "BM25-Regex"
        },
        "RAG_BM25_Stopword_Rerank_FINAL": {
            "reranker_class": "BM25StopwordReranker",
            "description": "BM25 Stopword",
            "model_name": "BM25-Stopword"
        },
        
        # CrossEncoder ê³„ì—´
        "RAG_CE_MiniLM_L6_Rerank_FINAL": {
            "reranker_class": "SentenceTransformerRerank",
            "description": "CrossEncoder MiniLM L6",
            "model_name": "cross-encoder/ms-marco-MiniLM-L-6-v2"
        },
        "RAG_CE_MiniLM_L12_Rerank_FINAL": {
            "reranker_class": "SentenceTransformerRerank", 
            "description": "CrossEncoder MiniLM L12",
            "model_name": "cross-encoder/ms-marco-MiniLM-L-12-v2"
        },
        
        # BGE ê³„ì—´
        "RAG_BGE_Base_Rerank_FINAL": {
            "reranker_class": "SentenceTransformerRerank",
            "description": "BGE Base",
            "model_name": "BAAI/bge-reranker-base"
        },
        
        # Embedding ê³„ì—´
        "RAG_EmbeddingCosine_E5_Rerank_FINAL": {
            "reranker_class": "EmbeddingCosineReranker",
            "description": "Embedding E5",
            "model_name": "intfloat/multilingual-e5-large-instruct"
        },
        "RAG_EmbeddingCosine_GTE_Rerank_FINAL": {
            "reranker_class": "EmbeddingCosineReranker",
            "description": "Embedding GTE", 
            "model_name": "thenlper/gte-multilingual-base"
        },
        
        # Hybrid ê³„ì—´
        "RAG_CombSum_Rerank_FINAL": {
            "reranker_class": "CombSumReranker",
            "description": "Hybrid CombSum",
            "model_name": "CombSum"
        },
        
        # LLM ê³„ì—´
        "RAG_LLM_Rerank_FINAL": {
            "reranker_class": "LLMReranker",
            "description": "LLM ê¸°ë³¸",
            "model_name": "gpt-4o-mini"
        },
        
        # Rules ê³„ì—´
        "RAG_LegalRuleBoost_Rerank_FINAL": {
            "reranker_class": "LegalRuleBoostReranker",
            "description": "Legal Rule Boost",
            "model_name": "LegalRuleBoost"
        }
    }
    
    return reranker_mappings.get(file_name, {
        "reranker_class": "BM25Reranker",
        "description": "Unknown",
        "model_name": "Unknown"
    })

def generate_v2_content(file_path: Path, info: Dict) -> str:
    """V2 ì¸í„°í˜ì´ìŠ¤ì— ë§ëŠ” íŒŒì¼ ë‚´ìš© ìƒì„±"""
    
    # í´ë˜ìŠ¤ ì´ë¦„ ì¶”ì¶œ
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ê¸°ì¡´ í´ë˜ìŠ¤ ì´ë¦„ ì°¾ê¸°
    class_match = re.search(r'class (LegalRAGSystem\w+):', content)
    class_name = class_match.group(1) if class_match else "LegalRAGSystemUnknown"
    
    # BGE ê³„ì—´ì¸ì§€ í™•ì¸
    is_bge = "BGE ê³„ì—´" in str(file_path)
    
    # ê²½ë¡œ ì„¤ì •
    if is_bge:
        path_setup = '''# ì„ë² ë”© íŒŒì¼ ê²½ë¡œ ì˜¬ë°”ë¥´ê²Œ ì„¤ì • (BGE ê³„ì—´ì€ 2ë‹¨ê³„ ìƒìœ„)
        if not os.path.isabs(embeddings_file):
            script_dir = os.path.dirname(os.path.abspath(__file__))
            self.embeddings_file = os.path.join(script_dir, "..", "..", "..", "output_chunks_with_embeddings.json")
            self.embeddings_file = os.path.normpath(self.embeddings_file)
        else:
            self.embeddings_file = embeddings_file'''
    else:
        path_setup = '''# ì„ë² ë”© íŒŒì¼ ê²½ë¡œ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •
        self.embeddings_file = get_embeddings_file_path(__file__, embeddings_file)'''
    
    # ë¦¬ë­ì»¤ ì„¤ì •
    reranker_class = info['reranker_class']
    model_name = info['model_name']
    
    if reranker_class == "SentenceTransformerRerank":
        reranker_init = f'''self.reranker = {reranker_class}(
            model_name="{model_name}",
            top_n=self.rerank_top_n,
        )'''
    elif reranker_class in ["EmbeddingCosineReranker"]:
        reranker_init = f'''self.reranker = {reranker_class}(
            top_n=self.rerank_top_n,
            embed_model_name="{model_name}"
        )'''
    else:
        reranker_init = f'''self.reranker = {reranker_class}(top_n=self.rerank_top_n)'''

    v2_content = f'''"""
ìƒˆë¡œìš´ í‘œì¤€ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” {info['description']} ë¦¬ë­ì»¤ V2
"""
import sys
import os
from pathlib import Path
from typing import List, Optional, Dict

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ fixed_base_v2 ëª¨ë“ˆ import
current_dir = Path(__file__).parent
parent_dir = current_dir.parent
{"parent_dir = parent_dir.parent  # BGE ê³„ì—´ì€ í•œ ë‹¨ê³„ ë”" if is_bge else ""}
sys.path.insert(0, str(parent_dir))

from fixed_base_v2 import (
    SentenceTransformerEmbeddings,
    NaiveVectorStore,
    BaseReranker,
    SimpleCompressionRetriever,
    load_embeddings_data,
    setup_environment,
    create_legal_prompt,
    format_docs,
    get_embeddings_file_path,
    {reranker_class}
)

from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough


class {class_name}:
    def __init__(self, embeddings_file: str = "output_chunks_with_embeddings.json", base_k: int = 80, rerank_top_n: int = 10):
        {path_setup}
        self.base_k = base_k
        self.rerank_top_n = rerank_top_n
        
        self.documents = []
        self.vectorstore = None
        self.retriever = None
        self.rag_chain = None
        self.llm = None
        self.embedding_model = None
        self.reranker = None

        self._setup_environment()
        self._initialize_system()

    def _setup_environment(self):
        setup_environment()

    def _load_embeddings_data(self) -> tuple:
        return load_embeddings_data(self.embeddings_file)

    def _create_vectorstore(self, documents, embeddings_array):
        print("ğŸ”§ Naive VectorStore ìƒì„± ì¤‘...")
        self.embedding_model = SentenceTransformerEmbeddings()
        vectorstore = NaiveVectorStore(
            documents=documents,
            embeddings=embeddings_array,
            embedding_function=self.embedding_model
        )
        print(f"âœ… Naive VectorStore ìƒì„± ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: {{len(documents)}})")
        return vectorstore

    def _setup_rag_components(self):
        print("âš™ï¸ RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì¤‘ ({info['description']} Re-ranker) ...")
        
        # ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
        base_retriever = self.vectorstore.as_retriever(search_kwargs={{"k": self.base_k}})
        
        # ë¦¬ë­ì»¤ ìƒì„±
        {reranker_init}
        
        # ì••ì¶• ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
        self.retriever = SimpleCompressionRetriever(base_retriever, self.reranker)

        # í”„ë¡¬í”„íŠ¸ ë° LLM ì„¤ì •
        legal_prompt = create_legal_prompt()
        
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0,
            openai_api_key=os.getenv("OPENAI_API_KEY"),
        )

        # RAG ì²´ì¸ ì„¤ì •
        def get_context(question):
            docs = self.retriever.invoke(question)
            return format_docs(docs)
        
        self.rag_chain = (
            {{
                "context": get_context,
                "question": RunnablePassthrough(),
            }}
            | legal_prompt
            | self.llm
            | StrOutputParser()
        )
        print("âœ… RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì™„ë£Œ")

    def _initialize_system(self):
        print("ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
        try:
            self.documents, embeddings_array = self._load_embeddings_data()
            self.vectorstore = self._create_vectorstore(self.documents, embeddings_array)
            self._setup_rag_components()
            print("ğŸ‰ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {{e}}")
            raise

    def rerank_documents(
        self,
        query: str,
        candidate_documents: Optional[List[dict]] = None,
        model: str = "{info['model_name']}"
    ) -> dict:
        """
        ìƒˆë¡œìš´ í‘œì¤€ ì¸í„°í˜ì´ìŠ¤ - ë¦¬ë­í‚¹ë§Œ ìˆ˜í–‰
        
        Args:
            query (str): ì‚¬ìš©ì ì§ˆë¬¸/ê²€ìƒ‰ì–´
            candidate_documents (Optional[List[dict]]): í›„ë³´ ë¬¸ì„œë“¤
            model (str): ë¦¬ë­ì»¤ ëª¨ë¸/ë°©ì‹ (í…ŒìŠ¤íŠ¸ìš©)
            
        Returns:
            dict: {{'retrieved_docs': [{{'doc_id': str, 'chunk_index': int, 'score': float, 'filename': str, 'text': str}}, ...]}}
        """
        if candidate_documents is None:
            # í›„ë³´ ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê²€ìƒ‰ ìˆ˜í–‰
            candidate_documents = self.retriever.base_retriever.get_candidate_documents(query)
        
        return self.reranker.rerank_documents(query, candidate_documents)

    def search_and_rerank(self, query: str) -> dict:
        """ê²€ìƒ‰ + ë¦¬ë­í‚¹ì„ í•¨ê»˜ ìˆ˜í–‰í•˜ëŠ” ë©”ì„œë“œ"""
        return self.retriever.search_and_rerank(query)

    def ask_question(self, question: str, show_sources: bool = True) -> str:
        print(f"\\nğŸ¤– ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘: {{question}}")
        print("-" * 50)
        try:
            if show_sources:
                # ìƒˆë¡œìš´ ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©
                result = self.search_and_rerank(question)
                retrieved_docs = result['retrieved_docs']
                
                print("ğŸ“š **ì°¸ê³ í•œ ë¬¸ì„œ:**")
                for i, doc_info in enumerate(retrieved_docs, 1):
                    print(f"  {{i}}. {{doc_info['doc_id']}} (ì ìˆ˜: {{doc_info['score']:.4f}})")
                print()
                
            # OpenAI API í‚¤ê°€ ì—†ìœ¼ë©´ ê²€ìƒ‰ë§Œ ìˆ˜í–‰
            if not os.getenv("OPENAI_API_KEY"):
                return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ê²€ìƒ‰ë§Œ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤."
            
            response = self.rag_chain.invoke(question)
            print("ğŸ’¡ **ë‹µë³€:**")
            print(response)
            return response
        except Exception as e:
            error_msg = f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {{e}}"
            print(error_msg)
            return error_msg


def main():
    print("ğŸš€ ë²•ë¥  ë¬¸ì„œ RAG ì‹œìŠ¤í…œ ({info['description']} Re-ranker V2) ì‹œì‘")
    print("=" * 60)
    try:
        rag_system = {class_name}()
        
        # ìƒˆë¡œìš´ ì¸í„°í˜ì´ìŠ¤ í…ŒìŠ¤íŠ¸
        query = "ì¢…í•©ë¶€ë™ì‚°ì„¸ë²•ì˜ ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
        result = rag_system.search_and_rerank(query)
        
        print(f"ê²€ìƒ‰ ê²°ê³¼: {{len(result['retrieved_docs'])}}ê°œ ë¬¸ì„œ")
        for i, doc in enumerate(result['retrieved_docs'][:3], 1):
            print(f"{{i}}. {{doc['doc_id']}} (ì ìˆ˜: {{doc['score']:.4f}})")
            print(f"   ë‚´ìš©: {{doc['text'][:100]}}...")
        
        print("\\nâœ… í”„ë¡œê·¸ë¨ì´ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {{e}}")


if __name__ == "__main__":
    main()'''
    
    return v2_content

def convert_all_final_files():
    """ëª¨ë“  FINAL íŒŒì¼ë“¤ì„ V2ë¡œ ë³€í™˜"""
    base_dir = Path(__file__).parent
    
    # ë³€í™˜í•  í´ë”ë“¤
    folders = [
        "BM25_Reranker",
        "CrossEncoder", 
        "CrossEncoder/BGE ê³„ì—´",
        "Embedding_Reranker",
        "Hybrid_Reranker",
        "LLM_Reranker",
        "Rules_Reranker"
    ]
    
    converted_count = 0
    total_count = 0
    
    for folder in folders:
        folder_path = base_dir / folder
        if not folder_path.exists():
            continue
            
        print(f"\nğŸ“ {folder} í´ë” ì²˜ë¦¬ ì¤‘...")
        
        # FINAL íŒŒì¼ë“¤ ì°¾ê¸°
        final_files = list(folder_path.glob("*_FINAL.py"))
        
        for final_file in final_files:
            total_count += 1
            
            try:
                # ë¦¬ë­ì»¤ ì •ë³´ ì¶”ì¶œ
                info = get_reranker_info(final_file)
                
                # V2 ë‚´ìš© ìƒì„±
                v2_content = generate_v2_content(final_file, info)
                
                # V2 íŒŒì¼ ê²½ë¡œ ìƒì„±
                v2_file = final_file.parent / (final_file.stem.replace("_FINAL", "_V2") + ".py")
                
                # V2 íŒŒì¼ ì‘ì„±
                with open(v2_file, 'w', encoding='utf-8') as f:
                    f.write(v2_content)
                
                print(f"âœ… ë³€í™˜ ì™„ë£Œ: {final_file.name} â†’ {v2_file.name}")
                converted_count += 1
                
            except Exception as e:
                print(f"âŒ ë³€í™˜ ì‹¤íŒ¨: {final_file.name} - {e}")
    
    print(f"\nğŸ“Š ë³€í™˜ ê²°ê³¼: {converted_count}/{total_count} íŒŒì¼ ì„±ê³µ")
    return converted_count == total_count

if __name__ == "__main__":
    success = convert_all_final_files()
    if success:
        print("\nğŸ‰ ëª¨ë“  FINAL íŒŒì¼ë“¤ì´ V2 ì¸í„°í˜ì´ìŠ¤ë¡œ ì„±ê³µì ìœ¼ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("\nâš ï¸ ì¼ë¶€ íŒŒì¼ ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
