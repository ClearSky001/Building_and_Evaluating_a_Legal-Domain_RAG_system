{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef93b155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ GPU ì‚¬ìš© ê°€ëŠ¥: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "ğŸ“Š GPU ê°œìˆ˜: 1ê°œ\n",
      "ğŸ”§ ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤: cuda\n",
      "ğŸ’¾ GPU ì´ ë©”ëª¨ë¦¬: 11.99GB\n",
      "ğŸ• í‰ê°€ ì‹œì‘ ì‹œê°„: 2025-09-17 17:03:22\n",
      "BASE_DIR: c:\\Users\\Lenovo\\Study\\ë¶€ë™ì‚°ì„¸, Advanced RAGë¥¼ í™œìš©í•œ ìƒì„±í˜•AI ë²•ë¬´ìë¬¸ ì„œë¹„ìŠ¤ í”„ë¡œì íŠ¸\\RAG_Retriever_Reranker_Experiment\n",
      "RERANKERS_DIR: c:\\Users\\Lenovo\\Study\\ë¶€ë™ì‚°ì„¸, Advanced RAGë¥¼ í™œìš©í•œ ìƒì„±í˜•AI ë²•ë¬´ìë¬¸ ì„œë¹„ìŠ¤ í”„ë¡œì íŠ¸\\RAG_Retriever_Reranker_Experiment\\RAG_with_Various_Rerankers\n",
      "EMB_PATH exists: True\n",
      "QA_PATH exists: True\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ ì„¤ì •\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "import warnings\n",
    "import time\n",
    "from datetime import datetime\n",
    "import torch\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU ì„¤ì • ë° í™•ì¸\n",
    "def setup_gpu():\n",
    "    \"\"\"GPU ì„¤ì • ë° í™•ì¸\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        print(f\"ğŸš€ GPU ì‚¬ìš© ê°€ëŠ¥: {gpu_name}\")\n",
    "        print(f\"ğŸ“Š GPU ê°œìˆ˜: {gpu_count}ê°œ\")\n",
    "        print(f\"ğŸ”§ ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤: {device}\")\n",
    "        \n",
    "        # GPU ë©”ëª¨ë¦¬ ì •ë³´ ì¶œë ¥\n",
    "        total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"ğŸ’¾ GPU ì´ ë©”ëª¨ë¦¬: {total_memory:.2f}GB\")\n",
    "        \n",
    "        return device\n",
    "    else:\n",
    "        print(\"âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "# GPU ì„¤ì • ì‹¤í–‰\n",
    "DEVICE = setup_gpu()\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •\n",
    "BASE_DIR = Path.cwd()\n",
    "RERANKERS_DIR = BASE_DIR / \"RAG_with_Various_Rerankers\"\n",
    "EMB_PATH = BASE_DIR / \"output_chunks_with_embeddings.json\"\n",
    "QA_PATH = BASE_DIR / \"real_estate_tax_QA.json\"\n",
    "\n",
    "# íŒ¨í‚¤ì§€ ê²½ë¡œ ì¶”ê°€\n",
    "sys.path.insert(0, str(RERANKERS_DIR))\n",
    "\n",
    "print(f\"ğŸ• í‰ê°€ ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"BASE_DIR: {BASE_DIR}\")\n",
    "print(f\"RERANKERS_DIR: {RERANKERS_DIR}\")\n",
    "print(f\"EMB_PATH exists: {EMB_PATH.exists()}\")\n",
    "print(f\"QA_PATH exists: {QA_PATH.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc23120b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ì„ íƒëœ ëŒ€í‘œ ë¦¬ë­ì»¤: 5ê°œ\n",
      "ğŸ“Š ì „ì²´ ë¦¬ë­ì»¤: 28ê°œ\n",
      "\n",
      "ğŸ“‹ ì„ íƒëœ ëŒ€í‘œ ë¦¬ë­ì»¤:\n",
      "  1. BM25 ê¸°ë³¸ (BM25 ê³„ì—´)\n",
      "  2. Cohere ()\n",
      "  3. Hybrid CombSum (Hybrid ê³„ì—´)\n",
      "  4. LLM ê¸°ë³¸ (LLM ê³„ì—´)\n",
      "  5. Legal Rule Boost ()\n",
      "\n",
      "ğŸ“ˆ ì˜ˆìƒ í‰ê°€ ì‹œê°„: ì•½ 30-45ë¶„\n",
      "ğŸ’¾ ì˜ˆìƒ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 6-8GB\n"
     ]
    }
   ],
   "source": [
    "# ê° ì¹´í…Œê³ ë¦¬ë³„ ëŒ€í‘œ ë¦¬ë­ì»¤ 1ê°œì”© ì„ ë³„ (ì´ 7ê°œ)\n",
    "REPRESENTATIVE_RERANKER_MODULES = [\n",
    "    # BM25 ê³„ì—´ ëŒ€í‘œ (CPU ê¸°ë°˜, ë¹ ë¥´ê³  ì•ˆì •ì )\n",
    "    (\"BM25_Reranker.RAG_BM25_Rerank_FINAL\", \"BM25 ê¸°ë³¸\", \"LegalRAGSystemBM25Rerank\"),\n",
    "    \n",
    "    # CrossEncoder ê³„ì—´ ëŒ€í‘œ (Cohere Reranker)\n",
    "    (\"CrossEncoder.RAG_Cohere_Rerank_FINAL\", \"Cohere\", \"LegalRAGSystemCohereRerank\"),\n",
    "    \n",
    "    # BGE ê³„ì—´ ëŒ€í‘œ (ìµœì í™”ëœ ë²„ì „ - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ )(bge-reranker-v2-m3 ëª¨ë¸)\n",
    "    # (\"CrossEncoder.BGE ê³„ì—´.RAG_BGE_Base_Optimized_Rerank_FINAL\", \"BGE v2-m3\", \"LegalRAGSystemBGEBase\"),\n",
    "    \n",
    "    # Embedding ê³„ì—´ ëŒ€í‘œ (ì„ë² ë”© ê¸°ë°˜)\n",
    "    # (\"Embedding_Reranker.RAG_EmbeddingCosine_E5_Rerank_FINAL\", \"Embedding E5\", \"LegalRAGSystemEmbeddingE5\"),\n",
    "    \n",
    "    # Hybrid ê³„ì—´ ëŒ€í‘œ (ê²°í•© ë°©ë²•)\n",
    "    (\"Hybrid_Reranker.RAG_CombSum_Rerank_FINAL\", \"Hybrid CombSum\", \"LegalRAGSystemCombSum\"),\n",
    "    \n",
    "    # LLM ê³„ì—´ ëŒ€í‘œ (ëŒ€í™”í˜• AI)\n",
    "    (\"LLM_Reranker.RAG_LLM_Rerank_FINAL\", \"LLM ê¸°ë³¸\", \"LegalRAGSystemLLM\"),\n",
    "    \n",
    "    # Rules ê³„ì—´ (ê·œì¹™ ê¸°ë°˜)\n",
    "    (\"Rules_Reranker.RAG_LegalRuleBoost_Rerank_FINAL\", \"Legal Rule Boost\", \"LegalRAGSystemLegalRuleBoost\")\n",
    "]\n",
    "\n",
    "# ì „ì²´ ë¦¬ë­ì»¤ ëª©ë¡ (ë°±ì—…ìš©)\n",
    "ALL_RERANKER_MODULES = [\n",
    "    # BM25 ë¦¬ë­ì»¤ë“¤ (5ê°œ)\n",
    "    (\"BM25_Reranker.RAG_BM25_Rerank_FINAL\", \"BM25 ê¸°ë³¸\", \"LegalRAGSystemBM25Rerank\"),\n",
    "    (\"BM25_Reranker.RAG_BM25_CharNgram_Rerank_FINAL\", \"BM25 CharNgram\", \"LegalRAGSystemBM25CharNgram\"),\n",
    "    (\"BM25_Reranker.RAG_BM25_Kiwi_Rerank_FINAL\", \"BM25 Kiwi\", \"LegalRAGSystemBM25Kiwi\"),\n",
    "    (\"BM25_Reranker.RAG_BM25_Regex_Rerank_FINAL\", \"BM25 Regex\", \"LegalRAGSystemBM25Regex\"),\n",
    "    (\"BM25_Reranker.RAG_BM25_Stopword_Rerank_FINAL\", \"BM25 Stopword\", \"LegalRAGSystemBM25Stopword\"),\n",
    "    \n",
    "    # CrossEncoder ë¦¬ë­ì»¤ë“¤ (7ê°œ)\n",
    "    (\"CrossEncoder.RAG_CE_MiniLM_L6_Rerank_FINAL\", \"CrossEncoder MiniLM L6\", \"LegalRAGSystemMiniLML6\"),\n",
    "    (\"CrossEncoder.RAG_CE_MiniLM_L12_Rerank_FINAL\", \"CrossEncoder MiniLM L12\", \"LegalRAGSystemMiniLML12\"),\n",
    "    (\"CrossEncoder.RAG_CE_Electra_Rerank_FINAL\", \"CrossEncoder Electra\", \"LegalRAGSystemElectra\"),\n",
    "    (\"CrossEncoder.RAG_CE_E5_Mistral_Rerank_FINAL\", \"CrossEncoder E5 Mistral\", \"LegalRAGSystemE5Mistral\"),\n",
    "    (\"CrossEncoder.RAG_Cohere_Rerank_FINAL\", \"Cohere\", \"LegalRAGSystemCohereRerank\"),\n",
    "    (\"CrossEncoder.RAG_MXBAI_Rerank_FINAL\", \"MXBAI\", \"LegalRAGSystemMXBAI\"),\n",
    "    \n",
    "    # BGE ê³„ì—´ (4ê°œ)\n",
    "    (\"CrossEncoder.BGE ê³„ì—´.RAG_BGE_Base_Rerank_FINAL\", \"BGE Base\", \"LegalRAGSystemBGEBase\"),\n",
    "    (\"CrossEncoder.BGE ê³„ì—´.RAG_BGE_Large_Rerank_FINAL\", \"BGE Large\", \"LegalRAGSystemBGELarge\"),\n",
    "    (\"CrossEncoder.BGE ê³„ì—´.RAG_BGE_v2m3_Rerank_FINAL\", \"BGE v2 M3\", \"LegalRAGSystemBGEv2m3\"),\n",
    "    (\"CrossEncoder.BGE ê³„ì—´.RAG_Flashrank_BGEv2m3_Rerank_FINAL\", \"Flashrank BGE v2m3\", \"LegalRAGSystemFlashrankBGEv2m3\"),\n",
    "    \n",
    "    # Embedding ë¦¬ë­ì»¤ë“¤ (5ê°œ)\n",
    "    (\"Embedding_Reranker.RAG_EmbeddingCosine_E5_Rerank_FINAL\", \"Embedding E5\", \"LegalRAGSystemEmbeddingE5\"),\n",
    "    (\"Embedding_Reranker.RAG_EmbeddingCosine_GTE_Rerank_FINAL\", \"Embedding GTE\", \"LegalRAGSystemEmbeddingGTE\"),\n",
    "    (\"Embedding_Reranker.RAG_EmbeddingCosine_MPNet_Rerank_FINAL\", \"Embedding MPNet\", \"LegalRAGSystemEmbeddingMPNet\"),\n",
    "    (\"Embedding_Reranker.RAG_EmbeddingCosine_Paraphrase_Rerank_FINAL\", \"Embedding Paraphrase\", \"LegalRAGSystemEmbeddingParaphrase\"),\n",
    "    (\"Embedding_Reranker.RAG_EmbeddingCosine_Stella_Rerank_FINAL\", \"Embedding Stella\", \"LegalRAGSystemEmbeddingStella\"),\n",
    "    \n",
    "    # Hybrid ë¦¬ë­ì»¤ë“¤ (4ê°œ)\n",
    "    (\"Hybrid_Reranker.RAG_CombSum_Rerank_FINAL\", \"Hybrid CombSum\", \"LegalRAGSystemCombSum\"),\n",
    "    (\"Hybrid_Reranker.RAG_CombMNZ_Rerank_FINAL\", \"Hybrid CombMNZ\", \"LegalRAGSystemCombMNZ\"),\n",
    "    (\"Hybrid_Reranker.RAG_RRF_Rerank_FINAL\", \"Hybrid RRF\", \"LegalRAGSystemRRF\"),\n",
    "    (\"Hybrid_Reranker.RAG_WeightedSum_BM25_Embed_Rerank_FINAL\", \"Hybrid WeightedSum\", \"LegalRAGSystemWeightedSum\"),\n",
    "    \n",
    "    # LLM ë¦¬ë­ì»¤ë“¤ (3ê°œ)\n",
    "    (\"LLM_Reranker.RAG_LLM_Rerank_FINAL\", \"LLM ê¸°ë³¸\", \"LegalRAGSystemLLM\"),\n",
    "    (\"LLM_Reranker.RAG_LLM_Listwise_Rerank_FINAL\", \"LLM Listwise\", \"LegalRAGSystemLLMListwise\"),\n",
    "    (\"LLM_Reranker.RAG_LLM_Pairwise_Rerank_FINAL\", \"LLM Pairwise\", \"LegalRAGSystemLLMPairwise\"),\n",
    "    \n",
    "    # Rules ë¦¬ë­ì»¤ë“¤ (1ê°œ)\n",
    "    (\"Rules_Reranker.RAG_LegalRuleBoost_Rerank_FINAL\", \"Legal Rule Boost\", \"LegalRAGSystemLegalRuleBoost\")\n",
    "]\n",
    "\n",
    "# ì‚¬ìš©í•  ë¦¬ë­ì»¤ ì„ íƒ (ëŒ€í‘œ ë¦¬ë­ì»¤ ì‚¬ìš©)\n",
    "SELECTED_RERANKER_MODULES = REPRESENTATIVE_RERANKER_MODULES\n",
    "\n",
    "print(f\"ğŸ¯ ì„ íƒëœ ëŒ€í‘œ ë¦¬ë­ì»¤: {len(SELECTED_RERANKER_MODULES)}ê°œ\")\n",
    "print(f\"ğŸ“Š ì „ì²´ ë¦¬ë­ì»¤: {len(ALL_RERANKER_MODULES)}ê°œ\")\n",
    "\n",
    "# ë¦¬ë­ì»¤ ìœ í˜•ë³„ ë¶„ë¥˜\n",
    "reranker_types = {\n",
    "    'BM25': [name for module_path, name, class_name in SELECTED_RERANKER_MODULES if 'BM25' in name],\n",
    "    'CrossEncoder': [name for module_path, name, class_name in SELECTED_RERANKER_MODULES if 'CrossEncoder' in name],\n",
    "    'BGE': [name for module_path, name, class_name in SELECTED_RERANKER_MODULES if 'BGE' in name],\n",
    "    'Embedding': [name for module_path, name, class_name in SELECTED_RERANKER_MODULES if 'Embedding' in name],\n",
    "    'Hybrid': [name for module_path, name, class_name in SELECTED_RERANKER_MODULES if 'Hybrid' in name],\n",
    "    'LLM': [name for module_path, name, class_name in SELECTED_RERANKER_MODULES if 'LLM' in name],\n",
    "    'Rules': [name for module_path, name, class_name in SELECTED_RERANKER_MODULES if 'Rules' in name]\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ“‹ ì„ íƒëœ ëŒ€í‘œ ë¦¬ë­ì»¤:\")\n",
    "for i, (module_path, name, class_name) in enumerate(SELECTED_RERANKER_MODULES, 1):\n",
    "    category = \"\"\n",
    "    if 'BM25' in name:\n",
    "        category = \"BM25 ê³„ì—´\"\n",
    "    elif 'CrossEncoder' in name:\n",
    "        category = \"CrossEncoder ê³„ì—´\"\n",
    "    elif 'BGE' in name:\n",
    "        category = \"BGE ê³„ì—´\"\n",
    "    elif 'Embedding' in name:\n",
    "        category = \"Embedding ê³„ì—´\"\n",
    "    elif 'Hybrid' in name:\n",
    "        category = \"Hybrid ê³„ì—´\"\n",
    "    elif 'LLM' in name:\n",
    "        category = \"LLM ê³„ì—´\"\n",
    "    elif 'Rules' in name:\n",
    "        category = \"Rules ê³„ì—´\"\n",
    "    \n",
    "    print(f\"  {i}. {name} ({category})\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ì˜ˆìƒ í‰ê°€ ì‹œê°„: ì•½ 30-45ë¶„\")\n",
    "print(f\"ğŸ’¾ ì˜ˆìƒ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 6-8GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2b89a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š ì´ ì§ˆë¬¸-ë‹µë³€ ìŒ: 50ê°œ\n",
      "ğŸ“Š í‰ê°€ìš© ë°ì´í„°: 50ê°œ (ì „ì²´ ì‚¬ìš©)\n",
      "\n",
      "ğŸ“‹ ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 3ê°œ):\n",
      "  1. ì¢…í•©ë¶€ë™ì‚°ì„¸ì—ì„œ ê³µì œí•  ì¬ì‚°ì„¸ëŠ” ì–´ë–»ê²Œ ì‚°ì •í•´ì•¼ í•˜ë‚˜ìš”?...\n",
      "  2. 2012ë…„ë„ ì¢…í•©ë¶€ë™ì‚°ì„¸ ê³µì œ ì¬ì‚°ì„¸ëŠ” ì–´ë–»ê²Œ ê³„ì‚°í•´ì•¼ í•˜ë‚˜ìš”?...\n",
      "  3. ì¢…í•©ë¶€ë™ì‚°ì„¸ì˜ ê³µì œ ì¬ì‚°ì„¸ëŠ” ì–´ë–¤ ê³µì •ì‹œì¥ê°€ì•¡ë¹„ìœ¨ì„ ì ìš©í•´ì•¼ í•˜ë‚˜ìš”?...\n",
      "ğŸ’¾ ìƒ˜í”Œ ë°ì´í„° ì €ì¥ë¨: c:\\Users\\Lenovo\\Study\\ë¶€ë™ì‚°ì„¸, Advanced RAGë¥¼ í™œìš©í•œ ìƒì„±í˜•AI ë²•ë¬´ìë¬¸ ì„œë¹„ìŠ¤ í”„ë¡œì íŠ¸\\RAG_Retriever_Reranker_Experiment\\sampled_qa_data.json\n",
      "\n",
      "ğŸ“‹ í† í”½ë³„ ë¶„í¬:\n",
      "  í•©ì‚°ë°°ì œ: 8ê°œ\n",
      "  ê³µì œ: 7ê°œ\n",
      "  ë¶€ì†í† ì§€: 7ê°œ\n",
      "  í† ì§€ë¶„ë¥˜: 7ê°œ\n",
      "  í—Œë²•: 6ê°œ\n",
      "  ì‹ íƒ: 6ê°œ\n",
      "  ì§€ë¶„: 5ê°œ\n",
      "  ê¸°íƒ€: 2ê°œ\n",
      "  í‰ë“±: 1ê°œ\n",
      "  ê²½ì •: 1ê°œ\n",
      "\n",
      "â±ï¸  ì „ì²´ ë°ì´í„° ì‚¬ìš©ìœ¼ë¡œ ì˜ˆìƒ í‰ê°€ ì‹œê°„: ì•½ 45-60ë¶„\n"
     ]
    }
   ],
   "source": [
    "# ì •ë‹µ ë°ì´í„° ë¡œë“œ (ì „ì²´ 50ê°œ ì‚¬ìš©)\n",
    "with open(QA_PATH, 'r', encoding='utf-8') as f:\n",
    "    qa_data = json.load(f)\n",
    "\n",
    "print(f\"ğŸ“š ì´ ì§ˆë¬¸-ë‹µë³€ ìŒ: {len(qa_data)}ê°œ\")\n",
    "\n",
    "# ë™ì¼í•œ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì„¤ì •\n",
    "import random\n",
    "\n",
    "# ì¬í˜„ ê°€ëŠ¥í•œ ëœë¤ ì‹œë“œ ì„¤ì • (ë™ì¼í•œ ê²°ê³¼ë¥¼ ìœ„í•´)\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ìƒ˜í”Œ í¬ê¸° ì„¤ì • (í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 10ê°œ, ì „ì²´ í‰ê°€ìš©ìœ¼ë¡œ 50ê°œ)\n",
    "SAMPLE_SIZE = 50  # í…ŒìŠ¤íŠ¸ìš©: 10ê°œ, ì „ì²´ í‰ê°€ìš©: 50ê°œ\n",
    "\n",
    "if SAMPLE_SIZE >= len(qa_data):\n",
    "    # ì „ì²´ ë°ì´í„° ì‚¬ìš©\n",
    "    sampled_data = qa_data\n",
    "    print(f\"ğŸ“Š í‰ê°€ìš© ë°ì´í„°: {len(sampled_data)}ê°œ (ì „ì²´ ì‚¬ìš©)\")\n",
    "else:\n",
    "    # ë™ì¼í•œ ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹œë“œ ê³ ì •ìœ¼ë¡œ ì¬í˜„ ê°€ëŠ¥)\n",
    "    sampled_data = random.sample(qa_data, SAMPLE_SIZE)\n",
    "    print(f\"ğŸ“Š í‰ê°€ìš© ë°ì´í„°: {len(sampled_data)}ê°œ (ìƒ˜í”Œë§, ì‹œë“œ: {RANDOM_SEED})\")\n",
    "    print(f\"ğŸ”§ ìƒ˜í”Œ í¬ê¸°: {SAMPLE_SIZE}ê°œ\")\n",
    "\n",
    "# ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°\n",
    "print(f\"\\nğŸ“‹ ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 3ê°œ):\")\n",
    "for i, item in enumerate(sampled_data[:3]):\n",
    "    print(f\"  {i+1}. {item['question'][:50]}...\")\n",
    "\n",
    "# ë™ì¼í•œ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ë¡œë“œí•˜ëŠ” ê¸°ëŠ¥\n",
    "def save_sample_data(sample_data, filename=\"sampled_qa_data.json\"):\n",
    "    \"\"\"ìƒ˜í”Œ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "    sample_file = BASE_DIR / filename\n",
    "    with open(sample_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(sample_data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"ğŸ’¾ ìƒ˜í”Œ ë°ì´í„° ì €ì¥ë¨: {sample_file}\")\n",
    "    return sample_file\n",
    "\n",
    "def load_sample_data(filename=\"sampled_qa_data.json\"):\n",
    "    \"\"\"ì €ì¥ëœ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë¡œë“œ\"\"\"\n",
    "    sample_file = BASE_DIR / filename\n",
    "    if sample_file.exists():\n",
    "        with open(sample_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"ğŸ“‚ ìƒ˜í”Œ ë°ì´í„° ë¡œë“œë¨: {sample_file}\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"âŒ ìƒ˜í”Œ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {sample_file}\")\n",
    "        return None\n",
    "\n",
    "# í˜„ì¬ ìƒ˜í”Œ ë°ì´í„° ì €ì¥\n",
    "sample_file = save_sample_data(sampled_data)\n",
    "\n",
    "# í† í”½ë³„ ë¶„í¬ í™•ì¸\n",
    "topic_counts = {}\n",
    "for item in sampled_data:\n",
    "    topic = item['metadata']['topic']\n",
    "    topic_counts[topic] = topic_counts.get(topic, 0) + 1\n",
    "\n",
    "print(\"\\nğŸ“‹ í† í”½ë³„ ë¶„í¬:\")\n",
    "for topic, count in sorted(topic_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {topic}: {count}ê°œ\")\n",
    "\n",
    "print(f\"\\nâ±ï¸  ì „ì²´ ë°ì´í„° ì‚¬ìš©ìœ¼ë¡œ ì˜ˆìƒ í‰ê°€ ì‹œê°„: ì•½ 45-60ë¶„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c8ed6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAGAS íŒ¨í‚¤ì§€ê°€ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# RAGAS íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° import\n",
    "try:\n",
    "    import ragas\n",
    "    from ragas import evaluate\n",
    "    from ragas.metrics import (\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_relevancy\n",
    "    )\n",
    "    print(\"âœ… RAGAS íŒ¨í‚¤ì§€ê°€ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ“¦ RAGAS íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ragas[all]\"])\n",
    "    \n",
    "    # ë‹¤ì‹œ import\n",
    "    import ragas\n",
    "    from ragas import evaluate\n",
    "    from ragas.metrics import (\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_relevancy\n",
    "    )\n",
    "    print(\"âœ… RAGAS íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° import ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc37d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU ì‚¬ìš© ê°€ëŠ¥\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 0.00GB ì‚¬ìš© / 0.00GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "ğŸ”§ í‰ê°€ í•¨ìˆ˜ë“¤ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ìµœì í™”\n",
    "import gc\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"GPU ë©”ëª¨ë¦¬ ì •ë¦¬\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        print(\"ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n",
    "    gc.collect()\n",
    "\n",
    "def get_gpu_memory_info():\n",
    "    \"\"\"GPU ë©”ëª¨ë¦¬ ì •ë³´ ì¶œë ¥\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3  # GB\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3  # GB\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB\n",
    "        print(f\"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {allocated:.2f}GB ì‚¬ìš© / {cached:.2f}GB ìºì‹œ / {total:.2f}GB ì´ëŸ‰\")\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ê³„ì‚°\n",
    "        usage_percent = (allocated / total) * 100\n",
    "        if usage_percent > 80:\n",
    "            print(f\"âš ï¸ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤: {usage_percent:.1f}%\")\n",
    "            print(\"ğŸ’¡ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\")\n",
    "        \n",
    "        return allocated, cached, total\n",
    "    else:\n",
    "        print(\"âš ï¸ CUDA ì‚¬ìš© ë¶ˆê°€ - CPU ëª¨ë“œ\")\n",
    "        return 0, 0, 0\n",
    "\n",
    "def check_gpu_availability():\n",
    "    \"\"\"GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"âœ… GPU ì‚¬ìš© ê°€ëŠ¥\")\n",
    "        get_gpu_memory_info()\n",
    "    else:\n",
    "        print(\"âŒ GPU ì‚¬ìš© ë¶ˆê°€ - PyTorchê°€ CUDAë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ’¡ GPU ì‚¬ìš©ì„ ì›í•œë‹¤ë©´ CUDA ì§€ì› PyTorchë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:\")\n",
    "        print(\"   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "\n",
    "# GPU ìƒíƒœ í™•ì¸\n",
    "check_gpu_availability()\n",
    "\n",
    "# ë¦¬ë­ì»¤ ë¡œë“œ ë° ì´ˆê¸°í™” í•¨ìˆ˜\n",
    "def load_reranker(module_path: str, class_name: str) -> Any:\n",
    "    \"\"\"ë¦¬ë­ì»¤ ëª¨ë“ˆì„ ë™ì ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        # ë¡œë”© ì „ GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
    "        print(\"ğŸ“Š ë¡œë”© ì „ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\")\n",
    "        get_gpu_memory_info()\n",
    "        \n",
    "        module = __import__(module_path, fromlist=[class_name])\n",
    "        reranker_class = getattr(module, class_name)\n",
    "        \n",
    "        # GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ì •ë¦¬\n",
    "        if torch.cuda.is_available():\n",
    "            allocated, _, total = get_gpu_memory_info()\n",
    "            if allocated / total > 0.7:  # 70% ì´ìƒ ì‚¬ìš© ì‹œ\n",
    "                print(\"ğŸ§¹ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± - ì •ë¦¬ ì¤‘...\")\n",
    "                clear_gpu_memory()\n",
    "        \n",
    "        reranker = reranker_class(embeddings_file=str(EMB_PATH))\n",
    "        \n",
    "        # ë¡œë”© í›„ GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
    "        print(\"ğŸ“Š ë¡œë”© í›„ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\")\n",
    "        get_gpu_memory_info()\n",
    "        \n",
    "        return reranker\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {module_path} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        # ì‹¤íŒ¨ ì‹œì—ë„ ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "        if torch.cuda.is_available():\n",
    "            clear_gpu_memory()\n",
    "        return None\n",
    "\n",
    "# RAGAS í‰ê°€ë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„ í•¨ìˆ˜\n",
    "def prepare_ragas_data(sampled_data: List[Dict], reranker: Any, reranker_name: str) -> List[Dict]:\n",
    "    \"\"\"RAGAS í‰ê°€ë¥¼ ìœ„í•œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.\"\"\"\n",
    "    ragas_data = []\n",
    "    \n",
    "    for i, item in enumerate(sampled_data):\n",
    "        try:\n",
    "            question = item['question']\n",
    "            ground_truth = item['ground_truth']\n",
    "            ground_truth_contexts = item['ground_truth_contexts']\n",
    "            \n",
    "            # ë¦¬ë­ì»¤ë¡œ ë¬¸ì„œ ê²€ìƒ‰\n",
    "            docs = reranker.retriever.invoke(question)\n",
    "            \n",
    "            # RAGAS í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "            ragas_item = {\n",
    "                'question': question,\n",
    "                'answer': ground_truth,  # ì •ë‹µì„ ë‹µë³€ìœ¼ë¡œ ì‚¬ìš©\n",
    "                'contexts': [doc.page_content for doc in docs],\n",
    "                'ground_truth': ground_truth,\n",
    "                'ground_truths': ground_truth_contexts\n",
    "            }\n",
    "            ragas_data.append(ragas_item)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {reranker_name} - ì§ˆë¬¸ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return ragas_data\n",
    "\n",
    "# RAGAS í‰ê°€ ì‹¤í–‰ í•¨ìˆ˜ (RAGAS 0.2.x í˜¸í™˜)\n",
    "def evaluate_with_ragas(ragas_data: List[Dict], reranker_name: str) -> Dict[str, float]:\n",
    "    \"\"\"RAGAS ë©”íŠ¸ë¦­ìœ¼ë¡œ ë¦¬ë­ì»¤ë¥¼ í‰ê°€í•©ë‹ˆë‹¤ (RAGAS 0.2.x í˜¸í™˜).\"\"\"\n",
    "    try:\n",
    "        # RAGAS 0.2.x í˜¸í™˜ ë°ì´í„° ì¤€ë¹„\n",
    "        try:\n",
    "            from datasets import Dataset as HuggingFaceDataset\n",
    "            \n",
    "            # ë°ì´í„° êµ¬ì¡° ë³€í™˜\n",
    "            dataset_dict = {\n",
    "                'question': [item['question'] for item in ragas_data],\n",
    "                'answer': [item['answer'] for item in ragas_data],\n",
    "                'contexts': [item['contexts'] for item in ragas_data],\n",
    "                'ground_truth': [item['ground_truth'] for item in ragas_data],\n",
    "                'ground_truths': [item['ground_truths'] for item in ragas_data]\n",
    "            }\n",
    "            \n",
    "            eval_data = HuggingFaceDataset.from_dict(dataset_dict)\n",
    "            print(f\"âœ… HuggingFace Dataset ìƒì„± ì™„ë£Œ: {len(eval_data)}ê°œ ìƒ˜í”Œ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Dataset ìƒì„± ì‹¤íŒ¨, DataFrame ì‚¬ìš©: {e}\")\n",
    "            eval_data = pd.DataFrame(ragas_data)\n",
    "            print(f\"âœ… DataFrame ìƒì„± ì™„ë£Œ: {len(eval_data)}ê°œ ìƒ˜í”Œ\")\n",
    "        \n",
    "        # RAGAS í‰ê°€ ì‹¤í–‰\n",
    "        metrics = [\n",
    "            context_precision,\n",
    "            context_recall,\n",
    "            faithfulness,\n",
    "            answer_relevancy\n",
    "        ]\n",
    "        \n",
    "        # RAGAS 0.2.x í˜¸í™˜ evaluate í˜¸ì¶œ\n",
    "        try:\n",
    "            result = evaluate(eval_data, metrics=metrics)\n",
    "            \n",
    "            # ê²°ê³¼ ì¶”ì¶œ (RAGAS 0.2.x í˜¸í™˜)\n",
    "            scores = {}\n",
    "            metric_names = ['context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']\n",
    "            \n",
    "            if hasattr(result, 'to_pandas'):\n",
    "                # RAGAS 0.2.x ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "                result_df = result.to_pandas()\n",
    "                for metric in metric_names:\n",
    "                    if metric in result_df.columns:\n",
    "                        scores[metric] = float(result_df[metric].iloc[0])\n",
    "                    else:\n",
    "                        scores[metric] = 0.0\n",
    "            else:\n",
    "                # ë‹¤ë¥¸ í˜•ì‹ì˜ ê²°ê³¼ ì²˜ë¦¬\n",
    "                for metric in metric_names:\n",
    "                    if hasattr(result, metric):\n",
    "                        scores[metric] = float(getattr(result, metric))\n",
    "                    elif isinstance(result, dict) and metric in result:\n",
    "                        scores[metric] = float(result[metric])\n",
    "                    else:\n",
    "                        scores[metric] = 0.0\n",
    "            \n",
    "            # ì¢…í•© ì ìˆ˜ ê³„ì‚°\n",
    "            scores['overall_score'] = sum(scores.values()) / 4\n",
    "            \n",
    "            return scores\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ RAGAS evaluate ì‹¤íŒ¨: {e}\")\n",
    "            # ëŒ€ì•ˆ: ê¸°ë³¸ê°’ ë°˜í™˜\n",
    "            return {\n",
    "                'context_precision': 0.0,\n",
    "                'context_recall': 0.0,\n",
    "                'faithfulness': 0.0,\n",
    "                'answer_relevancy': 0.0,\n",
    "                'overall_score': 0.0\n",
    "            }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {reranker_name} í‰ê°€ ì‹¤íŒ¨: {e}\")\n",
    "        return {\n",
    "            'context_precision': 0.0,\n",
    "            'context_recall': 0.0,\n",
    "            'faithfulness': 0.0,\n",
    "            'answer_relevancy': 0.0,\n",
    "            'overall_score': 0.0\n",
    "        }\n",
    "\n",
    "print(\"ğŸ”§ í‰ê°€ í•¨ìˆ˜ë“¤ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30cdebf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU ìµœì í™” ì„¤ì • ì™„ë£Œ\n",
      "ğŸ”§ CUDA ë²„ì „: 12.6\n",
      "ğŸ”§ cuDNN ë²„ì „: 90701\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 0.00GB ì‚¬ìš© / 0.00GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "\n",
      "ğŸš€ GPU ì‚¬ìš© ëª¨ë“œë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ğŸ’¡ ë¦¬ë­ì»¤ ë¡œë”© ì‹œ GPUë¥¼ í™œìš©í•˜ì—¬ ë” ë¹ ë¥¸ ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# GPU ì‚¬ìš©ì„ ìœ„í•œ ì¶”ê°€ ì„¤ì •\n",
    "def configure_gpu_settings():\n",
    "    \"\"\"GPU ì‚¬ìš©ì„ ìœ„í•œ ìµœì í™” ì„¤ì •\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        # GPU ë©”ëª¨ë¦¬ í• ë‹¹ ë°©ì‹ ì„¤ì •\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'\n",
    "        \n",
    "        # GPU ë©”ëª¨ë¦¬ ìºì‹œ ì„¤ì •\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # GPU ë©”ëª¨ë¦¬ ìµœì í™”\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        \n",
    "        print(\"âœ… GPU ìµœì í™” ì„¤ì • ì™„ë£Œ\")\n",
    "        print(f\"ğŸ”§ CUDA ë²„ì „: {torch.version.cuda}\")\n",
    "        print(f\"ğŸ”§ cuDNN ë²„ì „: {torch.backends.cudnn.version()}\")\n",
    "        \n",
    "        # GPU ë©”ëª¨ë¦¬ ì •ë³´ ì¶œë ¥\n",
    "        get_gpu_memory_info()\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print(\"âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return False\n",
    "\n",
    "# GPU ì„¤ì • ì‹¤í–‰\n",
    "gpu_available = configure_gpu_settings()\n",
    "\n",
    "if gpu_available:\n",
    "    print(\"\\nğŸš€ GPU ì‚¬ìš© ëª¨ë“œë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    print(\"ğŸ’¡ ë¦¬ë­ì»¤ ë¡œë”© ì‹œ GPUë¥¼ í™œìš©í•˜ì—¬ ë” ë¹ ë¥¸ ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ GPU ì‚¬ìš©ì„ ì›í•œë‹¤ë©´ CUDA ì§€ì› PyTorchë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e67c607f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ëŒ€í‘œ ë¦¬ë­ì»¤ ë¡œë”© ì‹œì‘...\n",
      "================================================================================\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 0.00GB ì‚¬ìš© / 0.00GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "\n",
      "[1/5] ë¡œë”© ì¤‘: BM25 ê¸°ë³¸...\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 0.00GB ì‚¬ìš© / 0.00GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "ğŸ“Š ë¡œë”© ì „ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 0.00GB ì‚¬ìš© / 0.00GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 0.00GB ì‚¬ìš© / 0.00GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\n",
      "ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...\n",
      "ğŸ“‚ ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì¤‘: c:\\Users\\Lenovo\\Study\\ë¶€ë™ì‚°ì„¸, Advanced RAGë¥¼ í™œìš©í•œ ìƒì„±í˜•AI ë²•ë¬´ìë¬¸ ì„œë¹„ìŠ¤ í”„ë¡œì íŠ¸\\RAG_Retriever_Reranker_Experiment\\output_chunks_with_embeddings.json\n",
      "âœ… 1057ê°œì˜ ë¬¸ì„œ ì²­í¬ ë¡œë“œ ì™„ë£Œ\n",
      "ğŸ“„ ì²« ë²ˆì§¸ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°: ì–‘ë„ì†Œë“ì„¸ë¶€ê³¼ì²˜ë¶„ì·¨ì†Œ\n",
      "[ìˆ˜ì›ì§€ë²• 2007. 11. 28. ì„ ê³  2007êµ¬í•©3771 íŒê²° : í•­ì†Œ]\n",
      "ã€íŒì‹œì‚¬í•­ã€‘\n",
      "ì–‘ë„ì†Œë“ì„¸ ê°ë©´ëŒ€ìƒì—ì„œ ì œì™¸ë˜ëŠ” ê³ ê¸‰ì£¼íƒì— í•´ë‹¹í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ íŒë‹¨í•¨ì—...\n",
      "ğŸ”§ Naive VectorStore ìƒì„± ì¤‘...\n",
      "âœ… Naive VectorStore ìƒì„± ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: 1057)\n",
      "âš™ï¸ RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì¤‘ (BM25 ê¸°ë°˜ Re-ranker) ...\n",
      "âœ… RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì™„ë£Œ\n",
      "ğŸ‰ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\n",
      "ğŸ“Š ë¡œë”© í›„ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 2.09GB ì‚¬ìš© / 2.10GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "âœ… BM25 ê¸°ë³¸ ë¡œë“œ ì„±ê³µ (23.95ì´ˆ)\n",
      "\n",
      "[2/5] ë¡œë”© ì¤‘: Cohere...\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 2.09GB ì‚¬ìš© / 2.10GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "ğŸ“Š ë¡œë”© ì „ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 2.09GB ì‚¬ìš© / 2.10GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 2.09GB ì‚¬ìš© / 2.10GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\n",
      "ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...\n",
      "ğŸ“‚ ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì¤‘: c:\\Users\\Lenovo\\Study\\ë¶€ë™ì‚°ì„¸, Advanced RAGë¥¼ í™œìš©í•œ ìƒì„±í˜•AI ë²•ë¬´ìë¬¸ ì„œë¹„ìŠ¤ í”„ë¡œì íŠ¸\\RAG_Retriever_Reranker_Experiment\\output_chunks_with_embeddings.json\n",
      "âœ… 1057ê°œì˜ ë¬¸ì„œ ì²­í¬ ë¡œë“œ ì™„ë£Œ\n",
      "ğŸ“„ ì²« ë²ˆì§¸ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°: ì–‘ë„ì†Œë“ì„¸ë¶€ê³¼ì²˜ë¶„ì·¨ì†Œ\n",
      "[ìˆ˜ì›ì§€ë²• 2007. 11. 28. ì„ ê³  2007êµ¬í•©3771 íŒê²° : í•­ì†Œ]\n",
      "ã€íŒì‹œì‚¬í•­ã€‘\n",
      "ì–‘ë„ì†Œë“ì„¸ ê°ë©´ëŒ€ìƒì—ì„œ ì œì™¸ë˜ëŠ” ê³ ê¸‰ì£¼íƒì— í•´ë‹¹í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ íŒë‹¨í•¨ì—...\n",
      "ğŸ”§ Naive VectorStore ìƒì„± ì¤‘...\n",
      "âœ… Naive VectorStore ìƒì„± ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: 1057)\n",
      "âš™ï¸ RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì¤‘ (Cohere Reranker) ...\n",
      "âœ… Cohere API í‚¤ í™•ì¸ë¨: ucB3BnfN2Q...\n",
      "âœ… RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì™„ë£Œ\n",
      "ğŸ‰ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\n",
      "ğŸ“Š ë¡œë”© í›„ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 4.26GB ì‚¬ìš© / 4.28GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "âœ… Cohere ë¡œë“œ ì„±ê³µ (9.20ì´ˆ)\n",
      "\n",
      "[3/5] ë¡œë”© ì¤‘: Hybrid CombSum...\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 4.26GB ì‚¬ìš© / 4.28GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "ğŸ“Š ë¡œë”© ì „ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 4.26GB ì‚¬ìš© / 4.28GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 4.26GB ì‚¬ìš© / 4.28GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\n",
      "ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...\n",
      "ğŸ“‚ ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì¤‘: c:\\Users\\Lenovo\\Study\\ë¶€ë™ì‚°ì„¸, Advanced RAGë¥¼ í™œìš©í•œ ìƒì„±í˜•AI ë²•ë¬´ìë¬¸ ì„œë¹„ìŠ¤ í”„ë¡œì íŠ¸\\RAG_Retriever_Reranker_Experiment\\output_chunks_with_embeddings.json\n",
      "âœ… 1057ê°œì˜ ë¬¸ì„œ ì²­í¬ ë¡œë“œ ì™„ë£Œ\n",
      "ğŸ“„ ì²« ë²ˆì§¸ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°: ì–‘ë„ì†Œë“ì„¸ë¶€ê³¼ì²˜ë¶„ì·¨ì†Œ\n",
      "[ìˆ˜ì›ì§€ë²• 2007. 11. 28. ì„ ê³  2007êµ¬í•©3771 íŒê²° : í•­ì†Œ]\n",
      "ã€íŒì‹œì‚¬í•­ã€‘\n",
      "ì–‘ë„ì†Œë“ì„¸ ê°ë©´ëŒ€ìƒì—ì„œ ì œì™¸ë˜ëŠ” ê³ ê¸‰ì£¼íƒì— í•´ë‹¹í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ íŒë‹¨í•¨ì—...\n",
      "ğŸ”§ Naive VectorStore ìƒì„± ì¤‘...\n",
      "âœ… Naive VectorStore ìƒì„± ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: 1057)\n",
      "âš™ï¸ RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì¤‘ (CombSum Hybrid Re-ranker) ...\n",
      "âœ… RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì™„ë£Œ\n",
      "ğŸ‰ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\n",
      "ğŸ“Š ë¡œë”© í›„ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 8.43GB ì‚¬ìš© / 8.46GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "âœ… Hybrid CombSum ë¡œë“œ ì„±ê³µ (11.79ì´ˆ)\n",
      "\n",
      "[4/5] ë¡œë”© ì¤‘: LLM ê¸°ë³¸...\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 8.43GB ì‚¬ìš© / 8.46GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "âš ï¸  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì´ˆê³¼ (8.43GB > 8.0GB). ì •ë¦¬ ì¤‘...\n",
      "ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 8.43GB ì‚¬ìš© / 8.46GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "ğŸ“Š ë¡œë”© ì „ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 8.43GB ì‚¬ìš© / 8.46GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 8.43GB ì‚¬ìš© / 8.46GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "ğŸ§¹ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± - ì •ë¦¬ ì¤‘...\n",
      "ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\n",
      "âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\n",
      "ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...\n",
      "ğŸ“‚ ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì¤‘: c:\\Users\\Lenovo\\Study\\ë¶€ë™ì‚°ì„¸, Advanced RAGë¥¼ í™œìš©í•œ ìƒì„±í˜•AI ë²•ë¬´ìë¬¸ ì„œë¹„ìŠ¤ í”„ë¡œì íŠ¸\\RAG_Retriever_Reranker_Experiment\\output_chunks_with_embeddings.json\n",
      "âœ… 1057ê°œì˜ ë¬¸ì„œ ì²­í¬ ë¡œë“œ ì™„ë£Œ\n",
      "ğŸ“„ ì²« ë²ˆì§¸ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°: ì–‘ë„ì†Œë“ì„¸ë¶€ê³¼ì²˜ë¶„ì·¨ì†Œ\n",
      "[ìˆ˜ì›ì§€ë²• 2007. 11. 28. ì„ ê³  2007êµ¬í•©3771 íŒê²° : í•­ì†Œ]\n",
      "ã€íŒì‹œì‚¬í•­ã€‘\n",
      "ì–‘ë„ì†Œë“ì„¸ ê°ë©´ëŒ€ìƒì—ì„œ ì œì™¸ë˜ëŠ” ê³ ê¸‰ì£¼íƒì— í•´ë‹¹í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ íŒë‹¨í•¨ì—...\n",
      "ğŸ”§ Naive VectorStore ìƒì„± ì¤‘...\n",
      "âœ… Naive VectorStore ìƒì„± ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: 1057)\n",
      "âš™ï¸ RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì¤‘ (LLM ê¸°ë°˜ Re-ranker) ...\n",
      "âœ… RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì™„ë£Œ\n",
      "ğŸ‰ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\n",
      "ğŸ“Š ë¡œë”© í›„ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 10.51GB ì‚¬ìš© / 10.54GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "âš ï¸ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤: 87.7%\n",
      "ğŸ’¡ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
      "âœ… LLM ê¸°ë³¸ ë¡œë“œ ì„±ê³µ (7.23ì´ˆ)\n",
      "\n",
      "[5/5] ë¡œë”© ì¤‘: Legal Rule Boost...\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 10.51GB ì‚¬ìš© / 10.54GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "âš ï¸ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤: 87.7%\n",
      "ğŸ’¡ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
      "âš ï¸  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì´ˆê³¼ (10.51GB > 8.0GB). ì •ë¦¬ ì¤‘...\n",
      "ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 10.51GB ì‚¬ìš© / 10.54GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "âš ï¸ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤: 87.7%\n",
      "ğŸ’¡ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
      "ğŸ“Š ë¡œë”© ì „ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 10.51GB ì‚¬ìš© / 10.54GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "âš ï¸ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤: 87.7%\n",
      "ğŸ’¡ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 10.51GB ì‚¬ìš© / 10.54GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "âš ï¸ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤: 87.7%\n",
      "ğŸ’¡ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
      "ğŸ§¹ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± - ì •ë¦¬ ì¤‘...\n",
      "ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\n",
      "âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\n",
      "ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...\n",
      "ğŸ“‚ ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì¤‘: c:\\Users\\Lenovo\\Study\\ë¶€ë™ì‚°ì„¸, Advanced RAGë¥¼ í™œìš©í•œ ìƒì„±í˜•AI ë²•ë¬´ìë¬¸ ì„œë¹„ìŠ¤ í”„ë¡œì íŠ¸\\RAG_Retriever_Reranker_Experiment\\output_chunks_with_embeddings.json\n",
      "âœ… 1057ê°œì˜ ë¬¸ì„œ ì²­í¬ ë¡œë“œ ì™„ë£Œ\n",
      "ğŸ“„ ì²« ë²ˆì§¸ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°: ì–‘ë„ì†Œë“ì„¸ë¶€ê³¼ì²˜ë¶„ì·¨ì†Œ\n",
      "[ìˆ˜ì›ì§€ë²• 2007. 11. 28. ì„ ê³  2007êµ¬í•©3771 íŒê²° : í•­ì†Œ]\n",
      "ã€íŒì‹œì‚¬í•­ã€‘\n",
      "ì–‘ë„ì†Œë“ì„¸ ê°ë©´ëŒ€ìƒì—ì„œ ì œì™¸ë˜ëŠ” ê³ ê¸‰ì£¼íƒì— í•´ë‹¹í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ íŒë‹¨í•¨ì—...\n",
      "ğŸ”§ Naive VectorStore ìƒì„± ì¤‘...\n",
      "âœ… Naive VectorStore ìƒì„± ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: 1057)\n",
      "âš™ï¸ RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì¤‘ (Legal Rule Boost Re-ranker) ...\n",
      "âœ… RAG ì»´í¬ë„ŒíŠ¸ ì„¤ì • ì™„ë£Œ\n",
      "ğŸ‰ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\n",
      "ğŸ“Š ë¡œë”© í›„ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 14.69GB ì‚¬ìš© / 14.72GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "âš ï¸ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤: 122.4%\n",
      "ğŸ’¡ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
      "âœ… Legal Rule Boost ë¡œë“œ ì„±ê³µ (11.64ì´ˆ)\n",
      "\n",
      "ğŸ“Š ë¡œë”© ê²°ê³¼:\n",
      "  âœ… ì„±ê³µ: 5ê°œ\n",
      "  âŒ ì‹¤íŒ¨: 0ê°œ\n",
      "  ğŸ“ˆ ì„±ê³µë¥ : 100.0%\n",
      "ğŸ’¾ GPU ë©”ëª¨ë¦¬: 14.69GB ì‚¬ìš© / 14.72GB ìºì‹œ / 11.99GB ì´ëŸ‰\n",
      "âš ï¸ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤: 122.4%\n",
      "ğŸ’¡ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ¯ 5ê°œ ëŒ€í‘œ ë¦¬ë­ì»¤ë¡œ í‰ê°€ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ëŒ€í‘œ ë¦¬ë­ì»¤ ë¡œë“œ ë° í‰ê°€ ì‹¤í–‰\n",
    "print(\"ğŸš€ ëŒ€í‘œ ë¦¬ë­ì»¤ ë¡œë”© ì‹œì‘...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ì´ˆê¸° GPU ë©”ëª¨ë¦¬ ìƒíƒœ\n",
    "get_gpu_memory_info()\n",
    "\n",
    "all_rerankers = {}\n",
    "success_count = 0\n",
    "failed_count = 0\n",
    "\n",
    "for i, (module_path, name, class_name) in enumerate(SELECTED_RERANKER_MODULES, 1):\n",
    "    print(f\"\\n[{i}/{len(SELECTED_RERANKER_MODULES)}] ë¡œë”© ì¤‘: {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸\n",
    "        allocated, cached, total = get_gpu_memory_info()\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ 8GB ì´ˆê³¼í•˜ë©´ ì •ë¦¬\n",
    "        if allocated > 8.0:\n",
    "            print(f\"âš ï¸  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì´ˆê³¼ ({allocated:.2f}GB > 8.0GB). ì •ë¦¬ ì¤‘...\")\n",
    "            clear_gpu_memory()\n",
    "            get_gpu_memory_info()\n",
    "        \n",
    "        reranker = load_reranker(module_path, class_name)\n",
    "        load_time = time.time() - start_time\n",
    "        \n",
    "        if reranker:\n",
    "            all_rerankers[name] = reranker\n",
    "            success_count += 1\n",
    "            print(f\"âœ… {name} ë¡œë“œ ì„±ê³µ ({load_time:.2f}ì´ˆ)\")\n",
    "        else:\n",
    "            failed_count += 1\n",
    "            print(f\"âŒ {name} ë¡œë“œ ì‹¤íŒ¨ ({load_time:.2f}ì´ˆ)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        failed_count += 1\n",
    "        print(f\"âŒ {name} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        clear_gpu_memory()  # ì‹¤íŒ¨ ì‹œ ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "\n",
    "print(f\"\\nğŸ“Š ë¡œë”© ê²°ê³¼:\")\n",
    "print(f\"  âœ… ì„±ê³µ: {success_count}ê°œ\")\n",
    "print(f\"  âŒ ì‹¤íŒ¨: {failed_count}ê°œ\")\n",
    "print(f\"  ğŸ“ˆ ì„±ê³µë¥ : {success_count/(success_count+failed_count)*100:.1f}%\")\n",
    "\n",
    "# ìµœì¢… GPU ë©”ëª¨ë¦¬ ìƒíƒœ\n",
    "get_gpu_memory_info()\n",
    "\n",
    "if success_count == 0:\n",
    "    print(\"âš ï¸  ë¡œë“œëœ ë¦¬ë­ì»¤ê°€ ì—†ìŠµë‹ˆë‹¤. í‰ê°€ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(f\"\\nğŸ¯ {success_count}ê°œ ëŒ€í‘œ ë¦¬ë­ì»¤ë¡œ í‰ê°€ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e6edff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” RAGAS ë²„ì „ ë° í˜¸í™˜ì„± í™•ì¸\n",
      "============================================================\n",
      "âœ… RAGAS ë²„ì „: 0.2.15\n",
      "ğŸ“‹ RAGAS ë²„ì „ ì •ë³´: 0.2.15\n",
      "âœ… RAGAS ë©”íŠ¸ë¦­ import ì„±ê³µ\n",
      "âœ… RAGAS 0.2.x ë²„ì „ í˜¸í™˜ imports ì„±ê³µ\n",
      "âœ… HuggingFace Dataset ì‚¬ìš© ê°€ëŠ¥\n",
      "ğŸ”§ ì‚¬ìš©í•  ë°ì´í„° íƒ€ì…: Dataset\n",
      "ğŸ”§ RAGAS í˜¸í™˜ì„± í™•ì¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# RAGAS ë²„ì „ í™•ì¸ ë° í˜¸í™˜ì„± ì²´í¬\n",
    "print(\"ğŸ” RAGAS ë²„ì „ ë° í˜¸í™˜ì„± í™•ì¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    import ragas\n",
    "    print(f\"âœ… RAGAS ë²„ì „: {ragas.__version__}\")\n",
    "    \n",
    "    # RAGAS ë²„ì „ì— ë”°ë¥¸ í˜¸í™˜ì„± í™•ì¸\n",
    "    ragas_version = ragas.__version__\n",
    "    print(f\"ğŸ“‹ RAGAS ë²„ì „ ì •ë³´: {ragas_version}\")\n",
    "    \n",
    "    # ì£¼ìš” ë©”íŠ¸ë¦­ import í…ŒìŠ¤íŠ¸\n",
    "    from ragas import evaluate\n",
    "    from ragas.metrics import (\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_relevancy\n",
    "    )\n",
    "    \n",
    "    # RAGAS 0.2.x ë²„ì „ìš© ì¶”ê°€ imports\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "    from ragas.llms import LangchainLLMWrapper\n",
    "    from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "    \n",
    "    print(\"âœ… RAGAS ë©”íŠ¸ë¦­ import ì„±ê³µ\")\n",
    "    print(\"âœ… RAGAS 0.2.x ë²„ì „ í˜¸í™˜ imports ì„±ê³µ\")\n",
    "    \n",
    "    # Dataset í´ë˜ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (RAGAS 0.2.x ë²„ì „ í˜¸í™˜)\n",
    "    USE_DATASET = False\n",
    "    try:\n",
    "        # RAGAS 0.2.xì—ì„œëŠ” Datasetì´ ë‹¤ë¥´ê²Œ êµ¬í˜„ë¨\n",
    "        from ragas import Dataset\n",
    "        print(\"âœ… RAGAS Dataset í´ë˜ìŠ¤ ì‚¬ìš© ê°€ëŠ¥\")\n",
    "        USE_DATASET = True\n",
    "    except ImportError:\n",
    "        try:\n",
    "            # ëŒ€ì•ˆ: datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©\n",
    "            from datasets import Dataset as HuggingFaceDataset\n",
    "            print(\"âœ… HuggingFace Dataset ì‚¬ìš© ê°€ëŠ¥\")\n",
    "            USE_DATASET = True\n",
    "        except ImportError:\n",
    "            print(\"âš ï¸ Dataset í´ë˜ìŠ¤ ì‚¬ìš© ë¶ˆê°€ - DataFrame ì‚¬ìš©\")\n",
    "            USE_DATASET = False\n",
    "    \n",
    "    print(f\"ğŸ”§ ì‚¬ìš©í•  ë°ì´í„° íƒ€ì…: {'Dataset' if USE_DATASET else 'DataFrame'}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ RAGAS import ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ RAGASë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:\")\n",
    "    print(\"   pip install ragas[all]\")\n",
    "\n",
    "print(\"ğŸ”§ RAGAS í˜¸í™˜ì„± í™•ì¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b946e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ RAGAS 0.2.x í˜¸í™˜ ê°œë³„ í‰ê°€ í•¨ìˆ˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# RAGAS 0.2.x ë²„ì „ í˜¸í™˜ ê°œë³„ í‰ê°€ í•¨ìˆ˜\n",
    "def evaluate_single_reranker_v2(reranker_name: str, reranker: Any, sampled_data: List[Dict]) -> Dict[str, float]:\n",
    "    \"\"\"ê°œë³„ ë¦¬ë­ì»¤ RAGAS í‰ê°€ í•¨ìˆ˜ (RAGAS 0.2.x í˜¸í™˜)\"\"\"\n",
    "    print(f\"\\nğŸ” {reranker_name} ê°œë³„ RAGAS í‰ê°€ ì‹œì‘...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ë°ì´í„° ì¤€ë¹„\n",
    "    start_time = time.time()\n",
    "    ragas_data = []\n",
    "    \n",
    "    print(f\"ğŸ“‹ {reranker_name} RAGAS ë°ì´í„° ì¤€ë¹„ ì¤‘...\")\n",
    "    for i, item in enumerate(sampled_data):\n",
    "        try:\n",
    "            question = item['question']\n",
    "            ground_truth = item['ground_truth']\n",
    "            ground_truth_contexts = item['ground_truth_contexts']\n",
    "            \n",
    "            # ë¦¬ë­ì»¤ë¡œ ë¬¸ì„œ ê²€ìƒ‰\n",
    "            docs = reranker.search(question, k=10)\n",
    "            \n",
    "            # RAGAS í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "            ragas_item = {\n",
    "                'question': question,\n",
    "                'answer': ground_truth,\n",
    "                'contexts': [doc.page_content for doc in docs],\n",
    "                'ground_truth': ground_truth,\n",
    "                'ground_truths': ground_truth_contexts\n",
    "            }\n",
    "            ragas_data.append(ragas_item)\n",
    "            \n",
    "            if (i + 1) % 5 == 0:\n",
    "                print(f\"  ì§„í–‰ë¥ : {i+1}/{len(sampled_data)} ({(i+1)/len(sampled_data)*100:.1f}%)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {reranker_name} - ì§ˆë¬¸ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "            continue\n",
    "    \n",
    "    prep_time = time.time() - start_time\n",
    "    print(f\"âœ… {reranker_name} ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ ({prep_time:.2f}ì´ˆ, {len(ragas_data)}ê°œ ìƒ˜í”Œ)\")\n",
    "    \n",
    "    if not ragas_data:\n",
    "        print(f\"âŒ {reranker_name} - í‰ê°€í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return {\n",
    "            'context_precision': 0.0,\n",
    "            'context_recall': 0.0,\n",
    "            'faithfulness': 0.0,\n",
    "            'answer_relevancy': 0.0,\n",
    "            'overall_score': 0.0\n",
    "        }\n",
    "    \n",
    "    print(f\"ğŸ¤– {reranker_name} RAGAS í‰ê°€ ì‹¤í–‰ ì¤‘...\")\n",
    "    \n",
    "    try:\n",
    "        # RAGAS 0.2.x ë²„ì „ìš© LLMê³¼ Embeddings ì„¤ì •\n",
    "        try:\n",
    "            from langchain_openai import ChatOpenAI\n",
    "            from ragas.llms import LangchainLLMWrapper\n",
    "            from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "            \n",
    "            # OpenAI LLM ì„¤ì • (í‰ê°€ìš©)\n",
    "            llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\", temperature=0))\n",
    "            \n",
    "            # ê¸°ì¡´ ë¦¬ë­ì»¤ì˜ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (intfloat/multilingual-e5-large-instruct)\n",
    "            # ë¦¬ë­ì»¤ì—ì„œ ì„ë² ë”© ëª¨ë¸ì„ ì¶”ì¶œí•˜ì—¬ RAGASìš©ìœ¼ë¡œ ë˜í•‘\n",
    "            embeddings = None\n",
    "            \n",
    "            # ë°©ë²• 1: ì§ì ‘ embedding_model ì†ì„± í™•ì¸\n",
    "            if hasattr(reranker, 'embedding_model') and reranker.embedding_model is not None:\n",
    "                embeddings = LangchainEmbeddingsWrapper(reranker.embedding_model)\n",
    "                print(f\"âœ… ê¸°ì¡´ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©: {type(reranker.embedding_model).__name__}\")\n",
    "            \n",
    "            # ë°©ë²• 2: retrieverë¥¼ í†µí•œ ì„ë² ë”© ëª¨ë¸ í™•ì¸\n",
    "            elif hasattr(reranker, 'retriever') and hasattr(reranker.retriever, 'embeddings'):\n",
    "                embeddings = LangchainEmbeddingsWrapper(reranker.retriever.embeddings)\n",
    "                print(f\"âœ… ê¸°ì¡´ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©: {type(reranker.retriever.embeddings).__name__}\")\n",
    "            \n",
    "            # ë°©ë²• 3: vectorstoreë¥¼ í†µí•œ ì„ë² ë”© ëª¨ë¸ í™•ì¸\n",
    "            elif hasattr(reranker, 'vectorstore') and hasattr(reranker.vectorstore, 'embedding_function'):\n",
    "                embeddings = LangchainEmbeddingsWrapper(reranker.vectorstore.embedding_function)\n",
    "                print(f\"âœ… ê¸°ì¡´ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©: {type(reranker.vectorstore.embedding_function).__name__}\")\n",
    "            \n",
    "            # ë°©ë²• 4: ëŒ€ì•ˆ - ê¸°ë³¸ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©\n",
    "            else:\n",
    "                from langchain_openai import OpenAIEmbeddings\n",
    "                embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
    "                print(f\"âš ï¸ ê¸°ë³¸ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (ê¸°ì¡´ ì„ë² ë”© ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ)\")\n",
    "                \n",
    "                # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥\n",
    "                print(f\"ğŸ” ë¦¬ë­ì»¤ ì†ì„± í™•ì¸:\")\n",
    "                print(f\"  - embedding_model: {hasattr(reranker, 'embedding_model')}\")\n",
    "                print(f\"  - retriever: {hasattr(reranker, 'retriever')}\")\n",
    "                print(f\"  - vectorstore: {hasattr(reranker, 'vectorstore')}\")\n",
    "                if hasattr(reranker, 'retriever'):\n",
    "                    print(f\"  - retriever.embeddings: {hasattr(reranker.retriever, 'embeddings')}\")\n",
    "                if hasattr(reranker, 'vectorstore'):\n",
    "                    print(f\"  - vectorstore.embedding_function: {hasattr(reranker.vectorstore, 'embedding_function')}\")\n",
    "            \n",
    "            print(f\"âœ… LLM ë° Embeddings ì„¤ì • ì™„ë£Œ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ LLM/Embeddings ì„¤ì • ì‹¤íŒ¨: {e}\")\n",
    "            llm = None\n",
    "            embeddings = None\n",
    "        \n",
    "        # RAGAS í‰ê°€ë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„\n",
    "        print(f\"ğŸ“Š RAGAS í‰ê°€ ë°ì´í„° ì¤€ë¹„ ì¤‘...\")\n",
    "        \n",
    "        # HuggingFace Dataset ì‚¬ìš© (RAGAS 0.2.x í˜¸í™˜)\n",
    "        try:\n",
    "            from datasets import Dataset as HuggingFaceDataset\n",
    "            \n",
    "            # ë°ì´í„° êµ¬ì¡° ë³€í™˜\n",
    "            dataset_dict = {\n",
    "                'question': [item['question'] for item in ragas_data],\n",
    "                'answer': [item['answer'] for item in ragas_data],\n",
    "                'contexts': [item['contexts'] for item in ragas_data],\n",
    "                'ground_truth': [item['ground_truth'] for item in ragas_data],\n",
    "                'ground_truths': [item['ground_truths'] for item in ragas_data]\n",
    "            }\n",
    "            \n",
    "            eval_data = HuggingFaceDataset.from_dict(dataset_dict)\n",
    "            print(f\"âœ… HuggingFace Dataset ìƒì„± ì™„ë£Œ: {len(eval_data)}ê°œ ìƒ˜í”Œ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Dataset ìƒì„± ì‹¤íŒ¨, DataFrame ì‚¬ìš©: {e}\")\n",
    "            eval_data = pd.DataFrame(ragas_data)\n",
    "            print(f\"âœ… DataFrame ìƒì„± ì™„ë£Œ: {len(eval_data)}ê°œ ìƒ˜í”Œ\")\n",
    "        \n",
    "        # RAGAS í‰ê°€ ì‹¤í–‰\n",
    "        from ragas.metrics import (\n",
    "            context_precision,\n",
    "            context_recall,\n",
    "            faithfulness,\n",
    "            answer_relevancy\n",
    "        )\n",
    "        \n",
    "        metrics = [\n",
    "            context_precision,\n",
    "            context_recall,\n",
    "            faithfulness,\n",
    "            answer_relevancy\n",
    "        ]\n",
    "        \n",
    "        print(f\"ğŸ” RAGAS ë©”íŠ¸ë¦­ ê³„ì‚° ì¤‘...\")\n",
    "        \n",
    "        # RAGAS 0.2.x ë²„ì „ í˜¸í™˜ evaluate í˜¸ì¶œ\n",
    "        try:\n",
    "            # RAGAS 0.2.xì—ì„œëŠ” metricsë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬í•˜ê³ , llmê³¼ embeddingsë¥¼ ë³„ë„ë¡œ ì„¤ì •\n",
    "            if llm and embeddings:\n",
    "                result = evaluate(\n",
    "                    eval_data,\n",
    "                    metrics=metrics,\n",
    "                    llm=llm,\n",
    "                    embeddings=embeddings\n",
    "                )\n",
    "            else:\n",
    "                # LLM/Embeddings ì—†ì´ í‰ê°€ ì‹œë„ (ê¸°ë³¸ ì„¤ì • ì‚¬ìš©)\n",
    "                result = evaluate(eval_data, metrics=metrics)\n",
    "            \n",
    "            print(f\"âœ… RAGAS í‰ê°€ ì™„ë£Œ\")\n",
    "            \n",
    "            # ê²°ê³¼ ì¶”ì¶œ (RAGAS 0.2.x í˜¸í™˜)\n",
    "            print(f\"ğŸ“Š RAGAS í‰ê°€ ê²°ê³¼ ì²˜ë¦¬ ì¤‘...\")\n",
    "            \n",
    "            scores = {}\n",
    "            metric_names = ['context_precision', 'context_recall', 'faithfulness', 'answer_relevancy']\n",
    "            \n",
    "            # RAGAS 0.2.x ê²°ê³¼ í˜•ì‹ì— ë§ê²Œ ì¶”ì¶œ\n",
    "            if hasattr(result, 'to_pandas'):\n",
    "                # RAGAS 0.2.x ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "                result_df = result.to_pandas()\n",
    "                for metric in metric_names:\n",
    "                    try:\n",
    "                        if metric in result_df.columns:\n",
    "                            scores[metric] = float(result_df[metric].iloc[0])\n",
    "                        else:\n",
    "                            print(f\"âš ï¸ {metric} ë©”íŠ¸ë¦­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                            scores[metric] = 0.0\n",
    "                    except Exception as e:\n",
    "                        print(f\"âš ï¸ {metric} ë©”íŠ¸ë¦­ ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "                        scores[metric] = 0.0\n",
    "            else:\n",
    "                # ë‹¤ë¥¸ í˜•ì‹ì˜ ê²°ê³¼ ì²˜ë¦¬\n",
    "                for metric in metric_names:\n",
    "                    try:\n",
    "                        if hasattr(result, metric):\n",
    "                            scores[metric] = float(getattr(result, metric))\n",
    "                        elif isinstance(result, dict) and metric in result:\n",
    "                            scores[metric] = float(result[metric])\n",
    "                        else:\n",
    "                            print(f\"âš ï¸ {metric} ë©”íŠ¸ë¦­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                            scores[metric] = 0.0\n",
    "                    except Exception as e:\n",
    "                        print(f\"âš ï¸ {metric} ë©”íŠ¸ë¦­ ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "                        scores[metric] = 0.0\n",
    "            \n",
    "            # ì¢…í•© ì ìˆ˜ ê³„ì‚°\n",
    "            scores['overall_score'] = (scores['context_precision'] + \n",
    "                                     scores['context_recall'] + \n",
    "                                     scores['faithfulness'] + \n",
    "                                     scores['answer_relevancy']) / 4\n",
    "            \n",
    "            print(f\"âœ… {reranker_name} RAGAS í‰ê°€ ì™„ë£Œ!\")\n",
    "            print(f\"ğŸ“Š ê²°ê³¼: CP={scores['context_precision']:.4f}, CR={scores['context_recall']:.4f}, \"\n",
    "                  f\"F={scores['faithfulness']:.4f}, AR={scores['answer_relevancy']:.4f}, \"\n",
    "                  f\"Overall={scores['overall_score']:.4f}\")\n",
    "            \n",
    "            return scores\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ RAGAS evaluate ì‹¤íŒ¨: {e}\")\n",
    "            print(f\"ğŸ”„ ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ í‰ê°€ ì‹œë„...\")\n",
    "            \n",
    "            # ëŒ€ì•ˆ: ê°œë³„ ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "            scores = {}\n",
    "            for metric in metrics:\n",
    "                try:\n",
    "                    # RAGAS 0.2.xì—ì„œëŠ” ë©”íŠ¸ë¦­ ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ\n",
    "                    metric_name = metric.name if hasattr(metric, 'name') else str(metric)\n",
    "                    scores[metric_name] = 0.0  # ì„ì‹œê°’\n",
    "                    print(f\"âœ… {metric_name} ê³„ì‚° ì™„ë£Œ (ì„ì‹œê°’)\")\n",
    "                except Exception as metric_error:\n",
    "                    print(f\"âš ï¸ {metric_name} ê³„ì‚° ì‹¤íŒ¨: {metric_error}\")\n",
    "                    scores[metric_name] = 0.0\n",
    "            \n",
    "            # í‘œì¤€ ë©”íŠ¸ë¦­ ì´ë¦„ìœ¼ë¡œ ë³€í™˜\n",
    "            standard_scores = {\n",
    "                'context_precision': scores.get('context_precision', 0.0),\n",
    "                'context_recall': scores.get('context_recall', 0.0),\n",
    "                'faithfulness': scores.get('faithfulness', 0.0),\n",
    "                'answer_relevancy': scores.get('answer_relevancy', 0.0)\n",
    "            }\n",
    "            standard_scores['overall_score'] = sum(standard_scores.values()) / 4\n",
    "            \n",
    "            return standard_scores\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {reranker_name} RAGAS í‰ê°€ ì‹¤íŒ¨: {e}\")\n",
    "        return {\n",
    "            'context_precision': 0.0,\n",
    "            'context_recall': 0.0,\n",
    "            'faithfulness': 0.0,\n",
    "            'answer_relevancy': 0.0,\n",
    "            'overall_score': 0.0\n",
    "        }\n",
    "\n",
    "print(\"ğŸ”§ RAGAS 0.2.x í˜¸í™˜ ê°œë³„ í‰ê°€ í•¨ìˆ˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d71cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Hybrid CombSum ë¦¬ë­ì»¤ ê°œë³„ RAGAS í‰ê°€\n",
      "================================================================================\n",
      "\n",
      "ğŸ” Hybrid CombSum ê°œë³„ RAGAS í‰ê°€ ì‹œì‘...\n",
      "============================================================\n",
      "ğŸ“‹ Hybrid CombSum RAGAS ë°ì´í„° ì¤€ë¹„ ì¤‘...\n"
     ]
    }
   ],
   "source": [
    "# Hybrid CombSum ë¦¬ë­ì»¤ í‰ê°€\n",
    "print(\"ğŸš€ Hybrid CombSum ë¦¬ë­ì»¤ ê°œë³„ RAGAS í‰ê°€\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'Hybrid CombSum' in all_rerankers:\n",
    "    hybrid_combsum_scores = evaluate_single_reranker_v2('Hybrid CombSum', all_rerankers['Hybrid CombSum'], sampled_data)\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    hybrid_combsum_results = pd.DataFrame([hybrid_combsum_scores], index=['Hybrid CombSum'])\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    hybrid_combsum_results.to_csv(f'hybrid_combsum_ragas_evaluation_{timestamp}.csv', encoding='utf-8-sig')\n",
    "    print(f\"\\nğŸ’¾ Hybrid CombSum ê²°ê³¼ ì €ì¥: hybrid_combsum_ragas_evaluation_{timestamp}.csv\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Hybrid CombSum ë¦¬ë­ì»¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    hybrid_combsum_scores = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad3a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr---m_7EFL-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
